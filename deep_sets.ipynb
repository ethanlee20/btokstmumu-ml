{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5295639e",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942ec52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product \n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from helpers import models, data, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb977a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "splits = [\"train\", \"val\"]\n",
    "levels = [\"gen\", \"det\", \"det_bkg\"]\n",
    "q_sq_veto = \"resonances\"\n",
    "\n",
    "dset_name = \"sets_unbinned\"\n",
    "\n",
    "def make_model_name(level, num_signal): return f\"deep_sets_{level}_{num_signal}\"\n",
    "\n",
    "dc9_new_phys = -0.82\n",
    "\n",
    "num_signal_per_set = [8_000, 16_000, 32_000]\n",
    "num_sets_per_label = {8_000 : 400, 16_000: 200, 32_000 : 100} \n",
    "num_sets_sensitivity = 2_000\n",
    "bkg_signal_ratio = 0.96\n",
    "charge_bkg_fraction = 0.33\n",
    "\n",
    "device = models.select_device()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr = 3e-4\n",
    "lr_reduce_factor = 0.8\n",
    "lr_reduce_patience = 5\n",
    "batch_sizes = {8_000 : 128, 16_000 : 64, 32_000 : 32}\n",
    "epochs = 100\n",
    "epochs_checkpoint = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c05299",
   "metadata": {},
   "source": [
    "Save standard scaling constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56430e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: det_bkg, 8000\n",
      "finished: det_bkg, 16000\n",
      "finished: det_bkg, 32000\n"
     ]
    }
   ],
   "source": [
    "split = \"train\"\n",
    "\n",
    "for level, num_signal in product((\"det_bkg\",), num_signal_per_set):\n",
    "\n",
    "        sets_features, sets_labels = data.make_sets(\n",
    "            level,\n",
    "            split,\n",
    "            q_sq_veto,\n",
    "            num_signal,\n",
    "            num_sets_per_label[num_signal],\n",
    "            bkg_signal_ratio=bkg_signal_ratio,\n",
    "            charge_bkg_fraction=charge_bkg_fraction\n",
    "        )\n",
    "\n",
    "        std_scale_mean = torch.mean(sets_features, dim=(0,1))\n",
    "        std_scale_std = torch.std(sets_features, dim=(0,1))\n",
    "\n",
    "        data.save_dset_file(std_scale_mean, dset_name, level, split, \"mean\", num_signal_per_set=num_signal)\n",
    "        data.save_dset_file(std_scale_std, dset_name, level, split, \"std\", num_signal_per_set=num_signal)\n",
    "\n",
    "        print(f\"finished: {level}, {num_signal}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a28e6b",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608053b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: gen, 8000\n",
      "finished: gen, 8000\n",
      "finished: gen, 16000\n",
      "finished: gen, 16000\n",
      "finished: gen, 32000\n",
      "finished: gen, 32000\n",
      "finished: det, 8000\n",
      "finished: det, 8000\n",
      "finished: det, 16000\n",
      "finished: det, 16000\n",
      "finished: det, 32000\n",
      "finished: det, 32000\n",
      "finished: det_bkg, 8000\n",
      "finished: det_bkg, 8000\n",
      "finished: det_bkg, 16000\n",
      "finished: det_bkg, 16000\n",
      "finished: det_bkg, 32000\n",
      "finished: det_bkg, 32000\n"
     ]
    }
   ],
   "source": [
    "for level, num_signal, split in product(levels, num_signal_per_set, splits): \n",
    "\n",
    "    sets_features, sets_labels = data.make_sets(\n",
    "        level,\n",
    "        split,\n",
    "        q_sq_veto,\n",
    "        num_signal,\n",
    "        num_sets_per_label[num_signal],\n",
    "        bkg_signal_ratio=bkg_signal_ratio,\n",
    "        charge_bkg_fraction=charge_bkg_fraction\n",
    "    )\n",
    "\n",
    "    sets_features = data.apply_std_scale(sets_features, dset_name, level, num_signal_per_set=num_signal)\n",
    "\n",
    "    data.save_dset_file(sets_features, dset_name, level, split, \"features\", num_signal_per_set=num_signal)\n",
    "    data.save_dset_file(sets_labels, dset_name, level, split, \"labels\", num_signal_per_set=num_signal)\n",
    "\n",
    "    print(f\"finished: {level}, {num_signal}, {split}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027bf5a",
   "metadata": {},
   "source": [
    "Sensitivity datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ece01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "\n",
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    sets_features, sets_labels = data.make_sets(\n",
    "        level,\n",
    "        split,\n",
    "        num_signal,\n",
    "        num_sets_sensitivity,\n",
    "        label_subset=[dc9_new_phys],\n",
    "        bkg_signal_ratio=bkg_signal_ratio,\n",
    "        charge_bkg_fraction=charge_bkg_fraction\n",
    "    )\n",
    "\n",
    "    sets_features = data.apply_std_scale(sets_features, dset_name, level, num_signal_per_set=num_signal)\n",
    "\n",
    "    helpers.data.save_dset_file(sets_features, dset_name, level, split, \"sens_features\", num_signal_per_set=num_signal)\n",
    "    helpers.data.save_dset_file(sets_labels, dset_name, level, split, \"sens_labels\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635b6e5",
   "metadata": {},
   "source": [
    "Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26aaf298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.8513104915618896\n",
      "    Val loss: 0.8246209025382996\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.8224759697914124\n",
      "    Val loss: 0.8141427636146545\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.6249987483024597\n",
      "    Val loss: 0.19346164166927338\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.08777537196874619\n",
      "    Val loss: 0.04701065272092819\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.04012717306613922\n",
      "    Val loss: 0.040444936603307724\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.038309190422296524\n",
      "    Val loss: 0.03710710629820824\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.039631832391023636\n",
      "    Val loss: 0.042449597269296646\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.04094596579670906\n",
      "    Val loss: 0.03639537841081619\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.03658026456832886\n",
      "    Val loss: 0.03926221281290054\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.0379025824368\n",
      "    Val loss: 0.043648745864629745\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.038444530218839645\n",
      "    Val loss: 0.04133149981498718\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.037917353212833405\n",
      "    Val loss: 0.0358450673520565\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.036953043192625046\n",
      "    Val loss: 0.035450782626867294\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.037639036774635315\n",
      "    Val loss: 0.05876532196998596\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.03729981184005737\n",
      "    Val loss: 0.03511261194944382\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.03522508218884468\n",
      "    Val loss: 0.03435128182172775\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.03657188639044762\n",
      "    Val loss: 0.03824019432067871\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.036164358258247375\n",
      "    Val loss: 0.03664929419755936\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.035859350115060806\n",
      "    Val loss: 0.03378238528966904\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.035944614559412\n",
      "    Val loss: 0.03782781958580017\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.03407210856676102\n",
      "    Val loss: 0.03392647206783295\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.03481724485754967\n",
      "    Val loss: 0.03638257458806038\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.035162873566150665\n",
      "    Val loss: 0.03346889838576317\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.03406446799635887\n",
      "    Val loss: 0.03316476568579674\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.034548334777355194\n",
      "    Val loss: 0.03934906795620918\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.0337136834859848\n",
      "    Val loss: 0.03324431553483009\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.036218367516994476\n",
      "    Val loss: 0.04315011203289032\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.03383784741163254\n",
      "    Val loss: 0.03304288536310196\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.03344098478555679\n",
      "    Val loss: 0.040707025676965714\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.03297383338212967\n",
      "    Val loss: 0.03350580856204033\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.03308581933379173\n",
      "    Val loss: 0.03263614699244499\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.035700492560863495\n",
      "    Val loss: 0.031766362488269806\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.0339018888771534\n",
      "    Val loss: 0.03199033811688423\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.03235136345028877\n",
      "    Val loss: 0.03353105112910271\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.03367586433887482\n",
      "    Val loss: 0.0314023531973362\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.03365518897771835\n",
      "    Val loss: 0.03501506149768829\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.03293284773826599\n",
      "    Val loss: 0.035838183015584946\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.03276123106479645\n",
      "    Val loss: 0.03158249706029892\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.03131780028343201\n",
      "    Val loss: 0.03168470412492752\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.03264375776052475\n",
      "    Val loss: 0.03321808949112892\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.032896753400564194\n",
      "    Val loss: 0.03158291429281235\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.03200206905603409\n",
      "    Val loss: 0.0360783152282238\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.031282588839530945\n",
      "    Val loss: 0.03068195842206478\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.031224524602293968\n",
      "    Val loss: 0.0313723050057888\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.030514249578118324\n",
      "    Val loss: 0.03927704319357872\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.03163689374923706\n",
      "    Val loss: 0.03092046268284321\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.030319983139634132\n",
      "    Val loss: 0.02992459386587143\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.03044240176677704\n",
      "    Val loss: 0.030126599594950676\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.02984795905649662\n",
      "    Val loss: 0.030643658712506294\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.030080672353506088\n",
      "    Val loss: 0.03260110691189766\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.030491279438138008\n",
      "    Val loss: 0.031317904591560364\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.03038395196199417\n",
      "    Val loss: 0.032239895313978195\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.030746856704354286\n",
      "    Val loss: 0.05124074965715408\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.031280919909477234\n",
      "    Val loss: 0.02936490625143051\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.029406582936644554\n",
      "    Val loss: 0.03279430791735649\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.029306532815098763\n",
      "    Val loss: 0.03171481937170029\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.029871352016925812\n",
      "    Val loss: 0.03690985590219498\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.02952834591269493\n",
      "    Val loss: 0.02997698448598385\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.028548464179039\n",
      "    Val loss: 0.028925666585564613\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.029284309595823288\n",
      "    Val loss: 0.02881786786019802\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.02961491420865059\n",
      "    Val loss: 0.02962203323841095\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.02899639494717121\n",
      "    Val loss: 0.02916591987013817\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.028590522706508636\n",
      "    Val loss: 0.028611404821276665\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.02856633998453617\n",
      "    Val loss: 0.028584012761712074\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.029323086142539978\n",
      "    Val loss: 0.028567692264914513\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.028663694858551025\n",
      "    Val loss: 0.028315573930740356\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.02911369316279888\n",
      "    Val loss: 0.028221018612384796\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.028776252642273903\n",
      "    Val loss: 0.028314316645264626\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.02853115275502205\n",
      "    Val loss: 0.028179246932268143\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.02808476611971855\n",
      "    Val loss: 0.028026409447193146\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.027556199580430984\n",
      "    Val loss: 0.029129382222890854\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.028218211606144905\n",
      "    Val loss: 0.031540703028440475\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.027759207412600517\n",
      "    Val loss: 0.02785203605890274\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.028083300217986107\n",
      "    Val loss: 0.028467271476984024\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.027835849672555923\n",
      "    Val loss: 0.028105981647968292\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.02788085676729679\n",
      "    Val loss: 0.028206193819642067\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.0276205912232399\n",
      "    Val loss: 0.027327051386237144\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.027184288948774338\n",
      "    Val loss: 0.027879633009433746\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.027806920930743217\n",
      "    Val loss: 0.027254221960902214\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.02694249153137207\n",
      "    Val loss: 0.03327034413814545\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.027905810624361038\n",
      "    Val loss: 0.029953068122267723\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.02684447355568409\n",
      "    Val loss: 0.02790714241564274\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.027307022362947464\n",
      "    Val loss: 0.02709663100540638\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.02671990543603897\n",
      "    Val loss: 0.02830127626657486\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.027428964152932167\n",
      "    Val loss: 0.03216291218996048\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.027109460905194283\n",
      "    Val loss: 0.026464415714144707\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.026364518329501152\n",
      "    Val loss: 0.02769298106431961\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.026208238676190376\n",
      "    Val loss: 0.027809245511889458\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.027012361213564873\n",
      "    Val loss: 0.0296111311763525\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.026699163019657135\n",
      "    Val loss: 0.026167791336774826\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.025640377774834633\n",
      "    Val loss: 0.02603161893785\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.025562161579728127\n",
      "    Val loss: 0.02629476971924305\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.026326486840844154\n",
      "    Val loss: 0.02689174748957157\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.02646016888320446\n",
      "    Val loss: 0.025899099186062813\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.025464477017521858\n",
      "    Val loss: 0.02686353027820587\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.026136813685297966\n",
      "    Val loss: 0.027089722454547882\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.025823108851909637\n",
      "    Val loss: 0.025869220495224\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.02591724507510662\n",
      "    Val loss: 0.026311570778489113\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.025435632094740868\n",
      "    Val loss: 0.026144487783312798\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.025591149926185608\n",
      "    Val loss: 0.026308543980121613\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "Training completed.\n",
      "finished: gen, 8000\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 1.0214530229568481\n",
      "    Val loss: 0.8361530303955078\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.8234221339225769\n",
      "    Val loss: 0.8204111456871033\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.8146296739578247\n",
      "    Val loss: 0.8096874952316284\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.7937413454055786\n",
      "    Val loss: 0.7818251252174377\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.7334192395210266\n",
      "    Val loss: 0.6514508724212646\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.2976682782173157\n",
      "    Val loss: 0.0677083432674408\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.04088571295142174\n",
      "    Val loss: 0.02502983808517456\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.022268300876021385\n",
      "    Val loss: 0.01946277730166912\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.020607424899935722\n",
      "    Val loss: 0.01821312867105007\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.02152499370276928\n",
      "    Val loss: 0.01813572272658348\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.01976812072098255\n",
      "    Val loss: 0.02004864066839218\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.019787216559052467\n",
      "    Val loss: 0.03633549064397812\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.021390456706285477\n",
      "    Val loss: 0.020215798169374466\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.019218197092413902\n",
      "    Val loss: 0.021063290536403656\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.019256269559264183\n",
      "    Val loss: 0.017620129510760307\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.01917458325624466\n",
      "    Val loss: 0.02265695109963417\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.01900738850235939\n",
      "    Val loss: 0.01846941001713276\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.020766358822584152\n",
      "    Val loss: 0.018166381865739822\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.018476177006959915\n",
      "    Val loss: 0.01942497119307518\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.01928187534213066\n",
      "    Val loss: 0.01762375421822071\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.01918511837720871\n",
      "    Val loss: 0.021527711302042007\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.01815892569720745\n",
      "    Val loss: 0.0179667379707098\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.017804237082600594\n",
      "    Val loss: 0.02172561176121235\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.01889919489622116\n",
      "    Val loss: 0.02434125356376171\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.018918726593255997\n",
      "    Val loss: 0.01731296256184578\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.018786519765853882\n",
      "    Val loss: 0.019859079271554947\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.018674103543162346\n",
      "    Val loss: 0.021020246669650078\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.019036676734685898\n",
      "    Val loss: 0.017223263159394264\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.0179129708558321\n",
      "    Val loss: 0.01691441982984543\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.019331516698002815\n",
      "    Val loss: 0.017107415944337845\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.01782049611210823\n",
      "    Val loss: 0.01690613478422165\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.018058037385344505\n",
      "    Val loss: 0.01702379249036312\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.017857959493994713\n",
      "    Val loss: 0.01691465638577938\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.01742582768201828\n",
      "    Val loss: 0.02000328339636326\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.018731769174337387\n",
      "    Val loss: 0.017665887251496315\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.017691900953650475\n",
      "    Val loss: 0.018876507878303528\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.01828918047249317\n",
      "    Val loss: 0.019280144944787025\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.017285162582993507\n",
      "    Val loss: 0.01904108189046383\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.01845511794090271\n",
      "    Val loss: 0.016696928068995476\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.017795763909816742\n",
      "    Val loss: 0.019006909802556038\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.017612449824810028\n",
      "    Val loss: 0.018932804465293884\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.017419736832380295\n",
      "    Val loss: 0.017337961122393608\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.01772104948759079\n",
      "    Val loss: 0.017705729231238365\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.016886845231056213\n",
      "    Val loss: 0.016670942306518555\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.018545309081673622\n",
      "    Val loss: 0.016449935734272003\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.017052505165338516\n",
      "    Val loss: 0.01851867511868477\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.01724170334637165\n",
      "    Val loss: 0.01758400909602642\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.01726662553846836\n",
      "    Val loss: 0.017080364748835564\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.016916347667574883\n",
      "    Val loss: 0.016454482451081276\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.017038624733686447\n",
      "    Val loss: 0.0168113075196743\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.017261020839214325\n",
      "    Val loss: 0.018268851563334465\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.016964279115200043\n",
      "    Val loss: 0.017473682761192322\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.016768326982855797\n",
      "    Val loss: 0.017162013798952103\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.01779485121369362\n",
      "    Val loss: 0.01819567196071148\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.016932692378759384\n",
      "    Val loss: 0.01715179719030857\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.01650695875287056\n",
      "    Val loss: 0.016456732526421547\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.01691480726003647\n",
      "    Val loss: 0.017298737540841103\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.016823798418045044\n",
      "    Val loss: 0.01632704958319664\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.016139429062604904\n",
      "    Val loss: 0.01621336117386818\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.016835391521453857\n",
      "    Val loss: 0.016998302191495895\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.01635301671922207\n",
      "    Val loss: 0.016540363430976868\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.016610603779554367\n",
      "    Val loss: 0.016570014879107475\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.016565877944231033\n",
      "    Val loss: 0.015982815995812416\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.017224948853254318\n",
      "    Val loss: 0.01626208983361721\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.016240572556853294\n",
      "    Val loss: 0.015987461432814598\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.016619451344013214\n",
      "    Val loss: 0.02329174429178238\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.01649078167974949\n",
      "    Val loss: 0.01600719802081585\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.017062172293663025\n",
      "    Val loss: 0.016138264909386635\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.017385872080922127\n",
      "    Val loss: 0.016082899644970894\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.016134148463606834\n",
      "    Val loss: 0.016583045944571495\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.016638174653053284\n",
      "    Val loss: 0.016041163355112076\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.016105161979794502\n",
      "    Val loss: 0.01736745983362198\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.016069574281573296\n",
      "    Val loss: 0.017372097820043564\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.015996720641851425\n",
      "    Val loss: 0.01612822897732258\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.01629479043185711\n",
      "    Val loss: 0.015872804448008537\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.01599610410630703\n",
      "    Val loss: 0.015845270827412605\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.016002105548977852\n",
      "    Val loss: 0.0160454660654068\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.016204049810767174\n",
      "    Val loss: 0.016139661893248558\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.016281351447105408\n",
      "    Val loss: 0.016047006472945213\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.01594056375324726\n",
      "    Val loss: 0.015828747302293777\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.016232429072260857\n",
      "    Val loss: 0.01591971144080162\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.016070377081632614\n",
      "    Val loss: 0.017108095809817314\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.016254935413599014\n",
      "    Val loss: 0.01570347137749195\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.0162307471036911\n",
      "    Val loss: 0.01597723364830017\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.016035109758377075\n",
      "    Val loss: 0.015824997797608376\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.01627054624259472\n",
      "    Val loss: 0.01582201197743416\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.016192419454455376\n",
      "    Val loss: 0.0156924556940794\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.016029562801122665\n",
      "    Val loss: 0.01604677364230156\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.01595236547291279\n",
      "    Val loss: 0.017774105072021484\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.01609707809984684\n",
      "    Val loss: 0.01573510840535164\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.016299381852149963\n",
      "    Val loss: 0.019473375752568245\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.016250604763627052\n",
      "    Val loss: 0.015792246907949448\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.015820307657122612\n",
      "    Val loss: 0.01650293357670307\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.016233770176768303\n",
      "    Val loss: 0.01618267595767975\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.015710100531578064\n",
      "    Val loss: 0.01641393080353737\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.015947233885526657\n",
      "    Val loss: 0.01675194315612316\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.015875009819865227\n",
      "    Val loss: 0.017011407762765884\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.016050083562731743\n",
      "    Val loss: 0.015474051237106323\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.015737902373075485\n",
      "    Val loss: 0.015523755922913551\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.016176139935851097\n",
      "    Val loss: 0.015494863502681255\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "Training completed.\n",
      "finished: gen, 16000\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.8418982625007629\n",
      "    Val loss: 0.8242765665054321\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.8249750137329102\n",
      "    Val loss: 0.8230518102645874\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.8224242329597473\n",
      "    Val loss: 0.8166840076446533\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.8005695939064026\n",
      "    Val loss: 0.7717083096504211\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.5369389057159424\n",
      "    Val loss: 0.19398866593837738\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.07715284079313278\n",
      "    Val loss: 0.017564332112669945\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.01690209098160267\n",
      "    Val loss: 0.015543545596301556\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.013107337057590485\n",
      "    Val loss: 0.015102412551641464\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.015790358185768127\n",
      "    Val loss: 0.01448205579072237\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.012366997078061104\n",
      "    Val loss: 0.013042417354881763\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.012057277373969555\n",
      "    Val loss: 0.012046377174556255\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.013143318705260754\n",
      "    Val loss: 0.010756940580904484\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.012280342169106007\n",
      "    Val loss: 0.009827254340052605\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.012690499424934387\n",
      "    Val loss: 0.010414734482765198\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.013181991875171661\n",
      "    Val loss: 0.009716801345348358\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.013022932223975658\n",
      "    Val loss: 0.013364508748054504\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.01176421158015728\n",
      "    Val loss: 0.01022177841514349\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.012575621716678143\n",
      "    Val loss: 0.013284340500831604\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.011870317161083221\n",
      "    Val loss: 0.014344257302582264\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.011499938555061817\n",
      "    Val loss: 0.010307670570909977\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.012513356283307076\n",
      "    Val loss: 0.009704974479973316\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.011895832605659962\n",
      "    Val loss: 0.009848677553236485\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.012571057304739952\n",
      "    Val loss: 0.009739833883941174\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.012029130011796951\n",
      "    Val loss: 0.009897721000015736\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.012185081839561462\n",
      "    Val loss: 0.014815758913755417\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.01224658451974392\n",
      "    Val loss: 0.009509718045592308\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.011458595283329487\n",
      "    Val loss: 0.01128758117556572\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.011405393481254578\n",
      "    Val loss: 0.010826291516423225\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.012354923412203789\n",
      "    Val loss: 0.009561087936162949\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.011369266547262669\n",
      "    Val loss: 0.009835504926741123\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.011306602507829666\n",
      "    Val loss: 0.010091084986925125\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.011697991751134396\n",
      "    Val loss: 0.009791777469217777\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.01121730636805296\n",
      "    Val loss: 0.009624441154301167\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.011409848928451538\n",
      "    Val loss: 0.009859470650553703\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.011293303221464157\n",
      "    Val loss: 0.011363031342625618\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.010941405780613422\n",
      "    Val loss: 0.012942709028720856\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.01117610651999712\n",
      "    Val loss: 0.009943044744431973\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.011369635351002216\n",
      "    Val loss: 0.009961387142539024\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.011457148939371109\n",
      "    Val loss: 0.01295147929340601\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.010395284742116928\n",
      "    Val loss: 0.01015357207506895\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.010562071576714516\n",
      "    Val loss: 0.009725267998874187\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.01122338231652975\n",
      "    Val loss: 0.009685786440968513\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.010623915120959282\n",
      "    Val loss: 0.01043801661580801\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.011028467677533627\n",
      "    Val loss: 0.011463356204330921\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.011251591145992279\n",
      "    Val loss: 0.009851978160440922\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.010743205435574055\n",
      "    Val loss: 0.00943076703697443\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.010127169080078602\n",
      "    Val loss: 0.010093936696648598\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.010976394638419151\n",
      "    Val loss: 0.0112788500264287\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.010815683752298355\n",
      "    Val loss: 0.011266358196735382\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.010980900377035141\n",
      "    Val loss: 0.00968894548714161\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.01116571482270956\n",
      "    Val loss: 0.01569533906877041\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.010570640675723553\n",
      "    Val loss: 0.01102401688694954\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.011673309840261936\n",
      "    Val loss: 0.015525918453931808\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.01048353873193264\n",
      "    Val loss: 0.011381996795535088\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.010183372534811497\n",
      "    Val loss: 0.012269813567399979\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.010310555808246136\n",
      "    Val loss: 0.014935770072042942\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.011179571971297264\n",
      "    Val loss: 0.009606406092643738\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.009936030954122543\n",
      "    Val loss: 0.010282897390425205\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.009870964102447033\n",
      "    Val loss: 0.009312611073255539\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.009957811795175076\n",
      "    Val loss: 0.00925152562558651\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.011120007373392582\n",
      "    Val loss: 0.009374143555760384\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.009920845739543438\n",
      "    Val loss: 0.009168670512735844\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.009777768515050411\n",
      "    Val loss: 0.009486885741353035\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.009821982122957706\n",
      "    Val loss: 0.00922421459108591\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.00990995392203331\n",
      "    Val loss: 0.00958549790084362\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.010416237637400627\n",
      "    Val loss: 0.009728217497467995\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.009997322224080563\n",
      "    Val loss: 0.00993673037737608\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.010412115603685379\n",
      "    Val loss: 0.009558689780533314\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.01022432092577219\n",
      "    Val loss: 0.009383016265928745\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.009809223935008049\n",
      "    Val loss: 0.009138349443674088\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.01016505528241396\n",
      "    Val loss: 0.009122076444327831\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.010459737852215767\n",
      "    Val loss: 0.009192864410579205\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.009627251885831356\n",
      "    Val loss: 0.009478832595050335\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.010121861472725868\n",
      "    Val loss: 0.010470057837665081\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.010303663089871407\n",
      "    Val loss: 0.009824487380683422\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.00965513288974762\n",
      "    Val loss: 0.009767292067408562\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.009752635844051838\n",
      "    Val loss: 0.010588867589831352\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.010229538194835186\n",
      "    Val loss: 0.009709370322525501\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.009861694648861885\n",
      "    Val loss: 0.010110260918736458\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.009560017846524715\n",
      "    Val loss: 0.009714999236166477\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.009635456837713718\n",
      "    Val loss: 0.012282516807317734\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.010093148797750473\n",
      "    Val loss: 0.009308891370892525\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.01008832361549139\n",
      "    Val loss: 0.009254817850887775\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.009647070430219173\n",
      "    Val loss: 0.010281352326273918\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.0098519092425704\n",
      "    Val loss: 0.009114478714764118\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.009877905249595642\n",
      "    Val loss: 0.009204836562275887\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.009639254771173\n",
      "    Val loss: 0.009050215594470501\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.00952687207609415\n",
      "    Val loss: 0.009116650559008121\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.009474743157625198\n",
      "    Val loss: 0.009154553525149822\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.0096437381580472\n",
      "    Val loss: 0.009242169559001923\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.009667998179793358\n",
      "    Val loss: 0.01136837899684906\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.009584592655301094\n",
      "    Val loss: 0.009169504977762699\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.009864832274615765\n",
      "    Val loss: 0.00911552645266056\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.009765318594872952\n",
      "    Val loss: 0.009285843931138515\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.009360036812722683\n",
      "    Val loss: 0.009174995124340057\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.009567875415086746\n",
      "    Val loss: 0.010093791410326958\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.009405377320945263\n",
      "    Val loss: 0.009035300463438034\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.00946869608014822\n",
      "    Val loss: 0.010803219862282276\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.009740252047777176\n",
      "    Val loss: 0.009140118956565857\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.009441970847547054\n",
      "    Val loss: 0.009182070381939411\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "Training completed.\n",
      "finished: gen, 32000\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.8940986394882202\n",
      "    Val loss: 0.8236731886863708\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.820980429649353\n",
      "    Val loss: 0.8169494867324829\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.8066197633743286\n",
      "    Val loss: 0.7887586951255798\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.7311872839927673\n",
      "    Val loss: 0.5638763904571533\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.22382070124149323\n",
      "    Val loss: 0.09342022240161896\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.0665062740445137\n",
      "    Val loss: 0.06768734753131866\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.05588362738490105\n",
      "    Val loss: 0.05821935087442398\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.057220976799726486\n",
      "    Val loss: 0.05936824530363083\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.051300711929798126\n",
      "    Val loss: 0.06610869616270065\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.0525544174015522\n",
      "    Val loss: 0.06709662079811096\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.050367385149002075\n",
      "    Val loss: 0.0556829608976841\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.05106823146343231\n",
      "    Val loss: 0.0633360743522644\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.05108153820037842\n",
      "    Val loss: 0.05669461935758591\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.04907701909542084\n",
      "    Val loss: 0.060121264308691025\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.047399647533893585\n",
      "    Val loss: 0.05324118584394455\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.04794342815876007\n",
      "    Val loss: 0.05295151472091675\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.048991017043590546\n",
      "    Val loss: 0.052791524678468704\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.04732774198055267\n",
      "    Val loss: 0.05408896878361702\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.04656163230538368\n",
      "    Val loss: 0.05179717391729355\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.04798845946788788\n",
      "    Val loss: 0.0571451410651207\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.04587477445602417\n",
      "    Val loss: 0.05448438227176666\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.04762966185808182\n",
      "    Val loss: 0.05069991201162338\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.045275311917066574\n",
      "    Val loss: 0.049640998244285583\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.046243805438280106\n",
      "    Val loss: 0.04929307475686073\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.04623612016439438\n",
      "    Val loss: 0.04930014908313751\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.04399123042821884\n",
      "    Val loss: 0.04923902451992035\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.04625101387500763\n",
      "    Val loss: 0.06182621791958809\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.04552188888192177\n",
      "    Val loss: 0.05148712918162346\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.04342786595225334\n",
      "    Val loss: 0.047728169709444046\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.04288312792778015\n",
      "    Val loss: 0.04763460531830788\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.04341212287545204\n",
      "    Val loss: 0.05044909566640854\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.04223184287548065\n",
      "    Val loss: 0.050193194299936295\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.04207533597946167\n",
      "    Val loss: 0.04979845508933067\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.041178688406944275\n",
      "    Val loss: 0.053883250802755356\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.04491632804274559\n",
      "    Val loss: 0.045728813856840134\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.04156741499900818\n",
      "    Val loss: 0.04783198609948158\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.04200183227658272\n",
      "    Val loss: 0.046359796077013016\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.04113565757870674\n",
      "    Val loss: 0.045068103820085526\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.04282137751579285\n",
      "    Val loss: 0.04833772033452988\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.041437484323978424\n",
      "    Val loss: 0.05117866396903992\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.040264613926410675\n",
      "    Val loss: 0.04708272963762283\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.03943637013435364\n",
      "    Val loss: 0.04825245589017868\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.03980176895856857\n",
      "    Val loss: 0.047745201736688614\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.04116389527916908\n",
      "    Val loss: 0.04362982138991356\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.03911242634057999\n",
      "    Val loss: 0.04238410294055939\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.039529185742139816\n",
      "    Val loss: 0.04313225299119949\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.039477765560150146\n",
      "    Val loss: 0.05084095522761345\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.03833042457699776\n",
      "    Val loss: 0.05294053629040718\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.0393994078040123\n",
      "    Val loss: 0.042504314333200455\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.038530465215444565\n",
      "    Val loss: 0.041510045528411865\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.038984548300504684\n",
      "    Val loss: 0.04130985960364342\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.03781126067042351\n",
      "    Val loss: 0.04113740473985672\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.03776456415653229\n",
      "    Val loss: 0.044692300260066986\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.03881731629371643\n",
      "    Val loss: 0.04152531549334526\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.03706873208284378\n",
      "    Val loss: 0.041616879403591156\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.0380096361041069\n",
      "    Val loss: 0.03964495658874512\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.03660308197140694\n",
      "    Val loss: 0.04243732988834381\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.035667963325977325\n",
      "    Val loss: 0.03884692117571831\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.03628462925553322\n",
      "    Val loss: 0.041037946939468384\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.03592108562588692\n",
      "    Val loss: 0.03929908946156502\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.03878552466630936\n",
      "    Val loss: 0.05198408663272858\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.03646938502788544\n",
      "    Val loss: 0.038208622485399246\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.035955652594566345\n",
      "    Val loss: 0.0385032594203949\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.03436649590730667\n",
      "    Val loss: 0.03777185082435608\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.03634815663099289\n",
      "    Val loss: 0.04077979177236557\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.035180747509002686\n",
      "    Val loss: 0.039480697363615036\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.03445781394839287\n",
      "    Val loss: 0.04381859675049782\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.03550263121724129\n",
      "    Val loss: 0.036724358797073364\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.034306600689888\n",
      "    Val loss: 0.04004562646150589\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.03429137542843819\n",
      "    Val loss: 0.0376550666987896\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.03660193085670471\n",
      "    Val loss: 0.04387825354933739\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.034878555685281754\n",
      "    Val loss: 0.04291385039687157\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.03345175087451935\n",
      "    Val loss: 0.035918574780225754\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.032585881650447845\n",
      "    Val loss: 0.03552685305476189\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.03287487104535103\n",
      "    Val loss: 0.03653799742460251\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.0336165614426136\n",
      "    Val loss: 0.040459759533405304\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.03308241814374924\n",
      "    Val loss: 0.035629354417324066\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.03183692321181297\n",
      "    Val loss: 0.03478766605257988\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.031598735600709915\n",
      "    Val loss: 0.03474386781454086\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.033853668719530106\n",
      "    Val loss: 0.0340137705206871\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.03383569046854973\n",
      "    Val loss: 0.03544416278600693\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.030995020642876625\n",
      "    Val loss: 0.03737162798643112\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.032756272703409195\n",
      "    Val loss: 0.036363162100315094\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.03205292671918869\n",
      "    Val loss: 0.036427441984415054\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.031036177650094032\n",
      "    Val loss: 0.033625856041908264\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.03180025517940521\n",
      "    Val loss: 0.036973241716623306\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.034308698028326035\n",
      "    Val loss: 0.03420836105942726\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.030811699107289314\n",
      "    Val loss: 0.03282974287867546\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.031351760029792786\n",
      "    Val loss: 0.03282521665096283\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.030375782400369644\n",
      "    Val loss: 0.040426790714263916\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.030779413878917694\n",
      "    Val loss: 0.03226977586746216\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.03019309602677822\n",
      "    Val loss: 0.03775555267930031\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.03172511234879494\n",
      "    Val loss: 0.03243459761142731\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.03007619082927704\n",
      "    Val loss: 0.035655755549669266\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.030343184247612953\n",
      "    Val loss: 0.03187672048807144\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.031585194170475006\n",
      "    Val loss: 0.031796474009752274\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.030680429190397263\n",
      "    Val loss: 0.03172793239355087\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.030302099883556366\n",
      "    Val loss: 0.03246001526713371\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.029896019026637077\n",
      "    Val loss: 0.033946674317121506\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.029101761057972908\n",
      "    Val loss: 0.034664902836084366\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "Training completed.\n",
      "finished: det, 8000\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.9753580689430237\n",
      "    Val loss: 0.8262766599655151\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.8244189620018005\n",
      "    Val loss: 0.8226244449615479\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.8228111267089844\n",
      "    Val loss: 0.8196886777877808\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.8159715533256531\n",
      "    Val loss: 0.8102872371673584\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.7911092042922974\n",
      "    Val loss: 0.7685220241546631\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.6531414985656738\n",
      "    Val loss: 0.25602611899375916\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.15446415543556213\n",
      "    Val loss: 0.11031405627727509\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.0762433260679245\n",
      "    Val loss: 0.050966061651706696\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.045087795704603195\n",
      "    Val loss: 0.04743916913866997\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.04125433787703514\n",
      "    Val loss: 0.04534297436475754\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.03349902480840683\n",
      "    Val loss: 0.04618622362613678\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.03558448702096939\n",
      "    Val loss: 0.0386466458439827\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.03497865051031113\n",
      "    Val loss: 0.044157613068819046\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.033754847943782806\n",
      "    Val loss: 0.03786978870630264\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.03308255225419998\n",
      "    Val loss: 0.03844217211008072\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.03417513519525528\n",
      "    Val loss: 0.03724333643913269\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.03227650001645088\n",
      "    Val loss: 0.05240805074572563\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.03706950694322586\n",
      "    Val loss: 0.039821818470954895\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.032670676708221436\n",
      "    Val loss: 0.03786655142903328\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.03243234008550644\n",
      "    Val loss: 0.036799825727939606\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.03466663882136345\n",
      "    Val loss: 0.03659806773066521\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.032039981335401535\n",
      "    Val loss: 0.037438493221998215\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.03181851655244827\n",
      "    Val loss: 0.03661802411079407\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.030679261311888695\n",
      "    Val loss: 0.03628526255488396\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.03163072094321251\n",
      "    Val loss: 0.03753390163183212\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.03160080313682556\n",
      "    Val loss: 0.03887522593140602\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.030875559896230698\n",
      "    Val loss: 0.03571486100554466\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.029398197308182716\n",
      "    Val loss: 0.03573082759976387\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.030959397554397583\n",
      "    Val loss: 0.050346046686172485\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.032784491777420044\n",
      "    Val loss: 0.03514230251312256\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.03034737892448902\n",
      "    Val loss: 0.03457999229431152\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.029925614595413208\n",
      "    Val loss: 0.0348445363342762\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.029032614082098007\n",
      "    Val loss: 0.044371478259563446\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.03016826882958412\n",
      "    Val loss: 0.03886809200048447\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.030661221593618393\n",
      "    Val loss: 0.03477654233574867\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.03208164870738983\n",
      "    Val loss: 0.036258213222026825\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.030121145769953728\n",
      "    Val loss: 0.035001397132873535\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.028480568900704384\n",
      "    Val loss: 0.03709462657570839\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.02832094579935074\n",
      "    Val loss: 0.03477095440030098\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.028548261150717735\n",
      "    Val loss: 0.03729104995727539\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.02973000705242157\n",
      "    Val loss: 0.03326113894581795\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.029782945290207863\n",
      "    Val loss: 0.0339975580573082\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.02808990329504013\n",
      "    Val loss: 0.03297559171915054\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.02871326543390751\n",
      "    Val loss: 0.03420286625623703\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.030082430690526962\n",
      "    Val loss: 0.038969479501247406\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.027683958411216736\n",
      "    Val loss: 0.03276670351624489\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.02857138216495514\n",
      "    Val loss: 0.033521439880132675\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.02669380232691765\n",
      "    Val loss: 0.03301133215427399\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.02805505134165287\n",
      "    Val loss: 0.03580765798687935\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.029049236327409744\n",
      "    Val loss: 0.03222949057817459\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.026439255103468895\n",
      "    Val loss: 0.03253990784287453\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.027744028717279434\n",
      "    Val loss: 0.03757741302251816\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.02689085155725479\n",
      "    Val loss: 0.033143363893032074\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.027423376217484474\n",
      "    Val loss: 0.03507346287369728\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.025780722498893738\n",
      "    Val loss: 0.031180238351225853\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.028685223311185837\n",
      "    Val loss: 0.03307861462235451\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.026973683387041092\n",
      "    Val loss: 0.035973984748125076\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.02638370171189308\n",
      "    Val loss: 0.030980050563812256\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.028583228588104248\n",
      "    Val loss: 0.03152153268456459\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.025717612355947495\n",
      "    Val loss: 0.03188932687044144\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.026338007301092148\n",
      "    Val loss: 0.03454430028796196\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.026826603338122368\n",
      "    Val loss: 0.038789473474025726\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.027803750708699226\n",
      "    Val loss: 0.032779302448034286\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.025923650711774826\n",
      "    Val loss: 0.031046150252223015\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.02600887045264244\n",
      "    Val loss: 0.030627446249127388\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.028588755056262016\n",
      "    Val loss: 0.030170273035764694\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.025644268840551376\n",
      "    Val loss: 0.03184112533926964\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.025860076770186424\n",
      "    Val loss: 0.030080700293183327\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.02508886344730854\n",
      "    Val loss: 0.030238071456551552\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.02450503222644329\n",
      "    Val loss: 0.02968212030827999\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.02538612112402916\n",
      "    Val loss: 0.030034834519028664\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.02596946246922016\n",
      "    Val loss: 0.02973775751888752\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.025097714737057686\n",
      "    Val loss: 0.031834714114665985\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.025286659598350525\n",
      "    Val loss: 0.03299540653824806\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.025204194709658623\n",
      "    Val loss: 0.03014008328318596\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.025365358218550682\n",
      "    Val loss: 0.02901323512196541\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.0247476939111948\n",
      "    Val loss: 0.03821982443332672\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.024509545415639877\n",
      "    Val loss: 0.03211410716176033\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.024816088378429413\n",
      "    Val loss: 0.028907161206007004\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.02388834021985531\n",
      "    Val loss: 0.030229181051254272\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.02466694451868534\n",
      "    Val loss: 0.029020261019468307\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.024055171757936478\n",
      "    Val loss: 0.029354317113757133\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.025479890406131744\n",
      "    Val loss: 0.028524275869131088\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.0251829344779253\n",
      "    Val loss: 0.029180975630879402\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.024946114048361778\n",
      "    Val loss: 0.03160780668258667\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.02468310296535492\n",
      "    Val loss: 0.028990156948566437\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.023763788864016533\n",
      "    Val loss: 0.034659262746572495\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.023677784949541092\n",
      "    Val loss: 0.02776334062218666\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.023054931312799454\n",
      "    Val loss: 0.03113386407494545\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.024365389719605446\n",
      "    Val loss: 0.02813814952969551\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.02339240163564682\n",
      "    Val loss: 0.033206161111593246\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.023050596937537193\n",
      "    Val loss: 0.029056904837489128\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.02414556033909321\n",
      "    Val loss: 0.028136851266026497\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.023795539513230324\n",
      "    Val loss: 0.02780947834253311\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.022864146158099174\n",
      "    Val loss: 0.029629996046423912\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.023749902844429016\n",
      "    Val loss: 0.028844008222222328\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.022426709532737732\n",
      "    Val loss: 0.027654128149151802\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.022163670510053635\n",
      "    Val loss: 0.026941774412989616\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.02245263010263443\n",
      "    Val loss: 0.029726408421993256\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.0229080431163311\n",
      "    Val loss: 0.028531137853860855\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.14 GB\n",
      "Training completed.\n",
      "finished: det, 16000\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.8997669816017151\n",
      "    Val loss: 0.8241654634475708\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.8241764903068542\n",
      "    Val loss: 0.8239830732345581\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.8231635689735413\n",
      "    Val loss: 0.8207083344459534\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.8165293335914612\n",
      "    Val loss: 0.8097942471504211\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.8040687441825867\n",
      "    Val loss: 0.788567066192627\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.7729038596153259\n",
      "    Val loss: 0.732279360294342\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.48234090209007263\n",
      "    Val loss: 0.1508319079875946\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.09787697345018387\n",
      "    Val loss: 0.049281176179647446\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.030717741698026657\n",
      "    Val loss: 0.0453096404671669\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.02352164313197136\n",
      "    Val loss: 0.045435212552547455\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.024202611297369003\n",
      "    Val loss: 0.021698929369449615\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.020833170041441917\n",
      "    Val loss: 0.021761901676654816\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.020611191168427467\n",
      "    Val loss: 0.02699182741343975\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.01932445541024208\n",
      "    Val loss: 0.02707795798778534\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.0186222642660141\n",
      "    Val loss: 0.025597216561436653\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.01976003497838974\n",
      "    Val loss: 0.031986311078071594\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.02007942833006382\n",
      "    Val loss: 0.03483281657099724\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.019765950739383698\n",
      "    Val loss: 0.02110108733177185\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.02281026914715767\n",
      "    Val loss: 0.02100887894630432\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.01741240918636322\n",
      "    Val loss: 0.024708982557058334\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.016861436888575554\n",
      "    Val loss: 0.02285010553896427\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.017897551879286766\n",
      "    Val loss: 0.021157950162887573\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.01876053772866726\n",
      "    Val loss: 0.020611105486750603\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.019989510998129845\n",
      "    Val loss: 0.02032870054244995\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.016918575391173363\n",
      "    Val loss: 0.02375640906393528\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.01779615506529808\n",
      "    Val loss: 0.026867972686886787\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.017511941492557526\n",
      "    Val loss: 0.02392059564590454\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.016684789210557938\n",
      "    Val loss: 0.02644549123942852\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.017941191792488098\n",
      "    Val loss: 0.026640931144356728\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.017054151743650436\n",
      "    Val loss: 0.02049390785396099\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.01907055638730526\n",
      "    Val loss: 0.04343263804912567\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.020085126161575317\n",
      "    Val loss: 0.025751929730176926\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.016903100535273552\n",
      "    Val loss: 0.02590520866215229\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.017607811838388443\n",
      "    Val loss: 0.0301724374294281\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.01734541542828083\n",
      "    Val loss: 0.029927218332886696\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.01845015212893486\n",
      "    Val loss: 0.02047034539282322\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.016691287979483604\n",
      "    Val loss: 0.023524459451436996\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.016875166445970535\n",
      "    Val loss: 0.01986117474734783\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.016355980187654495\n",
      "    Val loss: 0.02009529061615467\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.016610853374004364\n",
      "    Val loss: 0.027121521532535553\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.01693025976419449\n",
      "    Val loss: 0.022664258256554604\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.016157977283000946\n",
      "    Val loss: 0.022345736622810364\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.01725342683494091\n",
      "    Val loss: 0.020451273769140244\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.016514470800757408\n",
      "    Val loss: 0.021201318129897118\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.01631317473948002\n",
      "    Val loss: 0.02007541060447693\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.01650981232523918\n",
      "    Val loss: 0.022006062790751457\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.016546357423067093\n",
      "    Val loss: 0.024941878393292427\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.01594620570540428\n",
      "    Val loss: 0.021291252225637436\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.016166100278496742\n",
      "    Val loss: 0.019541457295417786\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.015980320051312447\n",
      "    Val loss: 0.03255418315529823\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.016354205086827278\n",
      "    Val loss: 0.020549168810248375\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.016290172934532166\n",
      "    Val loss: 0.023557664826512337\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.016656391322612762\n",
      "    Val loss: 0.020223192870616913\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.015506808646023273\n",
      "    Val loss: 0.020229630172252655\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.016116714105010033\n",
      "    Val loss: 0.02095726877450943\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.015956426039338112\n",
      "    Val loss: 0.01983071304857731\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.016426019370555878\n",
      "    Val loss: 0.02015899121761322\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.015882344916462898\n",
      "    Val loss: 0.019480416551232338\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.015460451133549213\n",
      "    Val loss: 0.01988155022263527\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.016094084829092026\n",
      "    Val loss: 0.02051035687327385\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.015121623873710632\n",
      "    Val loss: 0.02244049496948719\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.016360662877559662\n",
      "    Val loss: 0.021313456818461418\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.015795545652508736\n",
      "    Val loss: 0.01916874572634697\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.015333849005401134\n",
      "    Val loss: 0.026244282722473145\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.015826992690563202\n",
      "    Val loss: 0.032595161348581314\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.015802670270204544\n",
      "    Val loss: 0.020589318126440048\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.016132093966007233\n",
      "    Val loss: 0.0246683731675148\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.015841271728277206\n",
      "    Val loss: 0.019280895590782166\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.015920914709568024\n",
      "    Val loss: 0.020432593300938606\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.01531784888356924\n",
      "    Val loss: 0.01962532289326191\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.0157230906188488\n",
      "    Val loss: 0.01924981363117695\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.016406767070293427\n",
      "    Val loss: 0.02566932700574398\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.015206439420580864\n",
      "    Val loss: 0.023097852244973183\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.015689250081777573\n",
      "    Val loss: 0.020678911358118057\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.01565713621675968\n",
      "    Val loss: 0.022677792236208916\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.014910793863236904\n",
      "    Val loss: 0.021365936845541\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.014848296530544758\n",
      "    Val loss: 0.020831873640418053\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.015121552161872387\n",
      "    Val loss: 0.021033355966210365\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.015146462246775627\n",
      "    Val loss: 0.02061435952782631\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.015315502882003784\n",
      "    Val loss: 0.021253131330013275\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.015430470928549767\n",
      "    Val loss: 0.020857222378253937\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.01523507572710514\n",
      "    Val loss: 0.02247108705341816\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.015001323074102402\n",
      "    Val loss: 0.02306317910552025\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.015073293820023537\n",
      "    Val loss: 0.019336212426424026\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.014757098630070686\n",
      "    Val loss: 0.019621778279542923\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.014891140162944794\n",
      "    Val loss: 0.019743425771594048\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.015078835189342499\n",
      "    Val loss: 0.020432356745004654\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.014639039523899555\n",
      "    Val loss: 0.02287769690155983\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.015270549803972244\n",
      "    Val loss: 0.0197477787733078\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.014814130961894989\n",
      "    Val loss: 0.029074309393763542\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.014864304102957249\n",
      "    Val loss: 0.01976330205798149\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.014720373786985874\n",
      "    Val loss: 0.01978210359811783\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.014590234495699406\n",
      "    Val loss: 0.019278107210993767\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.014613330364227295\n",
      "    Val loss: 0.02268858812749386\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.014647101052105427\n",
      "    Val loss: 0.02143588289618492\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.01444044429808855\n",
      "    Val loss: 0.019839081913232803\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.014600381255149841\n",
      "    Val loss: 0.01907007396221161\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.014821074903011322\n",
      "    Val loss: 0.01928839273750782\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.014439682476222515\n",
      "    Val loss: 0.022326184436678886\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.014608683995902538\n",
      "    Val loss: 0.025435710325837135\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  1.15 GB\n",
      "Training completed.\n",
      "finished: det, 32000\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.8713581562042236\n",
      "    Val loss: 0.8249372243881226\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.8253002166748047\n",
      "    Val loss: 0.8246967792510986\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.8242783546447754\n",
      "    Val loss: 0.825316846370697\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.8236443400382996\n",
      "    Val loss: 0.8230178356170654\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.8225082159042358\n",
      "    Val loss: 0.8204874396324158\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.816952645778656\n",
      "    Val loss: 0.8118855953216553\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.8076688647270203\n",
      "    Val loss: 0.7952096462249756\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.6125591993331909\n",
      "    Val loss: 0.19396734237670898\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.10693607479333878\n",
      "    Val loss: 0.14060375094413757\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.08726707845926285\n",
      "    Val loss: 0.09787928313016891\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.08356480300426483\n",
      "    Val loss: 0.10144837200641632\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.08495144546031952\n",
      "    Val loss: 0.09108272939920425\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.07954062521457672\n",
      "    Val loss: 0.09529288113117218\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.08102861046791077\n",
      "    Val loss: 0.08642344921827316\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.08092209696769714\n",
      "    Val loss: 0.11423718184232712\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.0808006078004837\n",
      "    Val loss: 0.08651391416788101\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.07801304012537003\n",
      "    Val loss: 0.09509249776601791\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.07933293282985687\n",
      "    Val loss: 0.09273035824298859\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.07805710285902023\n",
      "    Val loss: 0.09476110339164734\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.07717382162809372\n",
      "    Val loss: 0.08744426816701889\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.07630351930856705\n",
      "    Val loss: 0.08846253156661987\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.07819216698408127\n",
      "    Val loss: 0.09568587690591812\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.07594266533851624\n",
      "    Val loss: 0.09033145755529404\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.07674512267112732\n",
      "    Val loss: 0.08990643918514252\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.07626783102750778\n",
      "    Val loss: 0.10133710503578186\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.0775391086935997\n",
      "    Val loss: 0.09638015180826187\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.07291168719530106\n",
      "    Val loss: 0.0901680439710617\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.07397637516260147\n",
      "    Val loss: 0.0948249101638794\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.0740165114402771\n",
      "    Val loss: 0.0834970474243164\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.07457791268825531\n",
      "    Val loss: 0.08719687908887863\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.07359897345304489\n",
      "    Val loss: 0.08276291191577911\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.07588911801576614\n",
      "    Val loss: 0.08316413313150406\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.07605022937059402\n",
      "    Val loss: 0.08352030813694\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.07212091237306595\n",
      "    Val loss: 0.0955885723233223\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.07357744872570038\n",
      "    Val loss: 0.11809046566486359\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.0725879967212677\n",
      "    Val loss: 0.07989071309566498\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.07818786054849625\n",
      "    Val loss: 0.0923607349395752\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.07273957133293152\n",
      "    Val loss: 0.09182833135128021\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.07207365334033966\n",
      "    Val loss: 0.09001696854829788\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.0714036375284195\n",
      "    Val loss: 0.07955683022737503\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.07155845314264297\n",
      "    Val loss: 0.09400489181280136\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.07247535139322281\n",
      "    Val loss: 0.08867353945970535\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.07220793515443802\n",
      "    Val loss: 0.1273137480020523\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.07346886396408081\n",
      "    Val loss: 0.08561994135379791\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.07122184336185455\n",
      "    Val loss: 0.08611202985048294\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.07292099297046661\n",
      "    Val loss: 0.11377465724945068\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.07079573720693588\n",
      "    Val loss: 0.07905251532793045\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.07684193551540375\n",
      "    Val loss: 0.08457278460264206\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.0693478137254715\n",
      "    Val loss: 0.08424437046051025\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.06959125399589539\n",
      "    Val loss: 0.08923164010047913\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.06944159418344498\n",
      "    Val loss: 0.07745638489723206\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.07023382931947708\n",
      "    Val loss: 0.07810268551111221\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.06984222680330276\n",
      "    Val loss: 0.10686655342578888\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.06940574944019318\n",
      "    Val loss: 0.07835286855697632\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.07269111275672913\n",
      "    Val loss: 0.10295628011226654\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.06966623663902283\n",
      "    Val loss: 0.09021314233541489\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.06807959824800491\n",
      "    Val loss: 0.0824851542711258\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.06832204759120941\n",
      "    Val loss: 0.08051956444978714\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.06878554075956345\n",
      "    Val loss: 0.10492397099733353\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.07038087397813797\n",
      "    Val loss: 0.08792439848184586\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.07005205750465393\n",
      "    Val loss: 0.1215396523475647\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.06891339272260666\n",
      "    Val loss: 0.09717149287462234\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.06913334131240845\n",
      "    Val loss: 0.07962798327207565\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.06703996658325195\n",
      "    Val loss: 0.08146103471517563\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.06679364293813705\n",
      "    Val loss: 0.10761100798845291\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.06798960268497467\n",
      "    Val loss: 0.0849127545952797\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.06712885946035385\n",
      "    Val loss: 0.07533212751150131\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.06743509322404861\n",
      "    Val loss: 0.07705939561128616\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.0681258961558342\n",
      "    Val loss: 0.0939449593424797\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.06726069748401642\n",
      "    Val loss: 0.07505092024803162\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.06650738418102264\n",
      "    Val loss: 0.09083720296621323\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.06602706760168076\n",
      "    Val loss: 0.08106347918510437\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.0660201758146286\n",
      "    Val loss: 0.07526995241641998\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.06669439375400543\n",
      "    Val loss: 0.08044250309467316\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.06803444027900696\n",
      "    Val loss: 0.0864701047539711\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.06605944037437439\n",
      "    Val loss: 0.09895624220371246\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.0657709613442421\n",
      "    Val loss: 0.07777296006679535\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.06722655892372131\n",
      "    Val loss: 0.08122220635414124\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.06654722988605499\n",
      "    Val loss: 0.08047444373369217\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.06602927297353745\n",
      "    Val loss: 0.09287063032388687\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.06601360440254211\n",
      "    Val loss: 0.09427846223115921\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.06543708592653275\n",
      "    Val loss: 0.07970428466796875\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.06495574861764908\n",
      "    Val loss: 0.07637098431587219\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.06542849540710449\n",
      "    Val loss: 0.07715015113353729\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.0655301958322525\n",
      "    Val loss: 0.10403122007846832\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.06531275808811188\n",
      "    Val loss: 0.08693335205316544\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.06521838158369064\n",
      "    Val loss: 0.0892816111445427\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.0646694004535675\n",
      "    Val loss: 0.12330874055624008\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.06512948125600815\n",
      "    Val loss: 0.0783277377486229\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.06477837264537811\n",
      "    Val loss: 0.08574307709932327\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.0639217346906662\n",
      "    Val loss: 0.07978261262178421\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.06446627527475357\n",
      "    Val loss: 0.07890547811985016\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.06412818282842636\n",
      "    Val loss: 0.1030854731798172\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.06423428654670715\n",
      "    Val loss: 0.08103794604539871\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.06383723020553589\n",
      "    Val loss: 0.0838579311966896\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.06479407101869583\n",
      "    Val loss: 0.08186567574739456\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.06408850848674774\n",
      "    Val loss: 0.07637713104486465\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.06414444744586945\n",
      "    Val loss: 0.0878421738743782\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.06386423856019974\n",
      "    Val loss: 0.08593202382326126\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.06373530626296997\n",
      "    Val loss: 0.07437170296907425\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "Training completed.\n",
      "finished: det_bkg, 8000\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.9008442759513855\n",
      "    Val loss: 0.8248478770256042\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.8252912759780884\n",
      "    Val loss: 0.823002815246582\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.8246235251426697\n",
      "    Val loss: 0.822627604007721\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.8229979276657104\n",
      "    Val loss: 0.8220146894454956\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.819548487663269\n",
      "    Val loss: 0.8253616094589233\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.8174837827682495\n",
      "    Val loss: 0.8134075403213501\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.8100483417510986\n",
      "    Val loss: 0.8054435849189758\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.7999629974365234\n",
      "    Val loss: 0.7882018685340881\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.7431322336196899\n",
      "    Val loss: 0.5925901532173157\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.21855637431144714\n",
      "    Val loss: 0.11548542231321335\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.06036990135908127\n",
      "    Val loss: 0.06369294226169586\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.06248456612229347\n",
      "    Val loss: 0.054657213389873505\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.05350194126367569\n",
      "    Val loss: 0.06435003131628036\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.05145896226167679\n",
      "    Val loss: 0.05363684147596359\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.05072302743792534\n",
      "    Val loss: 0.058515772223472595\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.05493663251399994\n",
      "    Val loss: 0.07881905138492584\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.05063765123486519\n",
      "    Val loss: 0.08243566751480103\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.05397224798798561\n",
      "    Val loss: 0.05677075684070587\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.04929225146770477\n",
      "    Val loss: 0.05797724798321724\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.04968094825744629\n",
      "    Val loss: 0.05547322332859039\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.04735444113612175\n",
      "    Val loss: 0.061643023043870926\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.05082925409078598\n",
      "    Val loss: 0.06571412831544876\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.049955952912569046\n",
      "    Val loss: 0.0666147843003273\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.04810864105820656\n",
      "    Val loss: 0.08789840340614319\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.05045145004987717\n",
      "    Val loss: 0.05747044086456299\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.0466214157640934\n",
      "    Val loss: 0.06312119960784912\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.04718642681837082\n",
      "    Val loss: 0.07300088554620743\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.04796074330806732\n",
      "    Val loss: 0.05341976881027222\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.04804764315485954\n",
      "    Val loss: 0.0749107375741005\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.05027361959218979\n",
      "    Val loss: 0.0704588070511818\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.048291634768247604\n",
      "    Val loss: 0.05615032836794853\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.047107428312301636\n",
      "    Val loss: 0.055988263338804245\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.05141415446996689\n",
      "    Val loss: 0.05590687692165375\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.04770161956548691\n",
      "    Val loss: 0.05452195927500725\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.045615389943122864\n",
      "    Val loss: 0.06738017499446869\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.04595891013741493\n",
      "    Val loss: 0.07472896575927734\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.04561983421444893\n",
      "    Val loss: 0.055612415075302124\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.04639574512839317\n",
      "    Val loss: 0.0896654799580574\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.04522137716412544\n",
      "    Val loss: 0.053105153143405914\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.04572756588459015\n",
      "    Val loss: 0.05361384153366089\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.045615773648023605\n",
      "    Val loss: 0.07039175927639008\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.047365572303533554\n",
      "    Val loss: 0.07038642466068268\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.04961599409580231\n",
      "    Val loss: 0.06630280613899231\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.044703274965286255\n",
      "    Val loss: 0.055116891860961914\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.044244591146707535\n",
      "    Val loss: 0.07212045043706894\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.04413223639130592\n",
      "    Val loss: 0.07286598533391953\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.0438898429274559\n",
      "    Val loss: 0.07473761588335037\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.04383722320199013\n",
      "    Val loss: 0.0651121586561203\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.04506008327007294\n",
      "    Val loss: 0.06100262701511383\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.04414532333612442\n",
      "    Val loss: 0.07239944487810135\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.04429176077246666\n",
      "    Val loss: 0.06975246965885162\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.045002080500125885\n",
      "    Val loss: 0.09040842950344086\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.0441766157746315\n",
      "    Val loss: 0.06667681038379669\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.043474990874528885\n",
      "    Val loss: 0.05584203079342842\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.04381537809967995\n",
      "    Val loss: 0.056159358471632004\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.04413909837603569\n",
      "    Val loss: 0.10361610352993011\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.045081738382577896\n",
      "    Val loss: 0.059620071202516556\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.04363175481557846\n",
      "    Val loss: 0.06896182894706726\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.042803455144166946\n",
      "    Val loss: 0.06079676374793053\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.043481793254613876\n",
      "    Val loss: 0.05645553767681122\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.04348495975136757\n",
      "    Val loss: 0.055559031665325165\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.04333382099866867\n",
      "    Val loss: 0.05628560110926628\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.04411178454756737\n",
      "    Val loss: 0.06182758882641792\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.04307134449481964\n",
      "    Val loss: 0.06634239852428436\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.04302949830889702\n",
      "    Val loss: 0.056792207062244415\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.042771391570568085\n",
      "    Val loss: 0.05930250510573387\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.04352657496929169\n",
      "    Val loss: 0.05767040699720383\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.043127331882715225\n",
      "    Val loss: 0.057296328246593475\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.04238875210285187\n",
      "    Val loss: 0.06034296378493309\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.04262673482298851\n",
      "    Val loss: 0.06917078793048859\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.04194546118378639\n",
      "    Val loss: 0.0563267320394516\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.042274631559848785\n",
      "    Val loss: 0.055233363062143326\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.04332498088479042\n",
      "    Val loss: 0.060018330812454224\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.04254758358001709\n",
      "    Val loss: 0.05349048972129822\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.042534150183200836\n",
      "    Val loss: 0.05674666911363602\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.04297859966754913\n",
      "    Val loss: 0.07335136830806732\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.041867755353450775\n",
      "    Val loss: 0.06266118586063385\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.04265862703323364\n",
      "    Val loss: 0.053237784653902054\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.042336393147706985\n",
      "    Val loss: 0.05530387908220291\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.042025141417980194\n",
      "    Val loss: 0.06486666202545166\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.042032625526189804\n",
      "    Val loss: 0.06542225182056427\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.042829729616642\n",
      "    Val loss: 0.06727541238069534\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.04160190373659134\n",
      "    Val loss: 0.050783734768629074\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.042246151715517044\n",
      "    Val loss: 0.06027607247233391\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.041688691824674606\n",
      "    Val loss: 0.05786745622754097\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.04201984778046608\n",
      "    Val loss: 0.06177792698144913\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.04195054993033409\n",
      "    Val loss: 0.06924459338188171\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.04167458787560463\n",
      "    Val loss: 0.05705748498439789\n",
      "\n",
      "Learning rate: [3.221225472000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.042550958693027496\n",
      "    Val loss: 0.058436427265405655\n",
      "\n",
      "Learning rate: [2.5769803776000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.04151960462331772\n",
      "    Val loss: 0.058970797806978226\n",
      "\n",
      "Learning rate: [2.5769803776000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.04152112081646919\n",
      "    Val loss: 0.06625571101903915\n",
      "\n",
      "Learning rate: [2.5769803776000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.041754186153411865\n",
      "    Val loss: 0.058532945811748505\n",
      "\n",
      "Learning rate: [2.5769803776000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.041644636541604996\n",
      "    Val loss: 0.061803851276636124\n",
      "\n",
      "Learning rate: [2.5769803776000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.04149569198489189\n",
      "    Val loss: 0.06106436625123024\n",
      "\n",
      "Learning rate: [2.5769803776000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.04175020009279251\n",
      "    Val loss: 0.05934086814522743\n",
      "\n",
      "Learning rate: [2.0615843020800013e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.04192623868584633\n",
      "    Val loss: 0.07035905122756958\n",
      "\n",
      "Learning rate: [2.0615843020800013e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.04181743785738945\n",
      "    Val loss: 0.06630443781614304\n",
      "\n",
      "Learning rate: [2.0615843020800013e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.0417955182492733\n",
      "    Val loss: 0.08072647452354431\n",
      "\n",
      "Learning rate: [2.0615843020800013e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.04142139479517937\n",
      "    Val loss: 0.058945946395397186\n",
      "\n",
      "Learning rate: [2.0615843020800013e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.041434146463871\n",
      "    Val loss: 0.05935976654291153\n",
      "\n",
      "Learning rate: [2.0615843020800013e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "Training completed.\n",
      "finished: det_bkg, 16000\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.9752506613731384\n",
      "    Val loss: 0.8300980925559998\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.8274438381195068\n",
      "    Val loss: 0.8253286480903625\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.8263140320777893\n",
      "    Val loss: 0.8224498629570007\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.8250837326049805\n",
      "    Val loss: 0.8254832029342651\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.8244064450263977\n",
      "    Val loss: 0.8241859674453735\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.8236855268478394\n",
      "    Val loss: 0.8229057788848877\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.8234844207763672\n",
      "    Val loss: 0.8218888640403748\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.8217089772224426\n",
      "    Val loss: 0.8213561773300171\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.8200676441192627\n",
      "    Val loss: 0.8168187141418457\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.8186261057853699\n",
      "    Val loss: 0.8165301084518433\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.8152434825897217\n",
      "    Val loss: 0.8151461482048035\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.8144910931587219\n",
      "    Val loss: 0.8088694214820862\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.8084739446640015\n",
      "    Val loss: 0.809952974319458\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.8024507164955139\n",
      "    Val loss: 0.8129140138626099\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.7947785258293152\n",
      "    Val loss: 0.7893263101577759\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.7822337746620178\n",
      "    Val loss: 0.8045997619628906\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.7570831775665283\n",
      "    Val loss: 0.7339864373207092\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.6941915154457092\n",
      "    Val loss: 0.595657467842102\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.3491915762424469\n",
      "    Val loss: 0.15635675191879272\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.09226435422897339\n",
      "    Val loss: 0.06105069816112518\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.05317944288253784\n",
      "    Val loss: 0.07382454723119736\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.03635639324784279\n",
      "    Val loss: 0.08164487779140472\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.045649200677871704\n",
      "    Val loss: 0.04987073317170143\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.034254636615514755\n",
      "    Val loss: 0.056873057037591934\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.034576356410980225\n",
      "    Val loss: 0.13187046349048615\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.03290063887834549\n",
      "    Val loss: 0.06826120615005493\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.03565913066267967\n",
      "    Val loss: 0.05254156142473221\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.03579862415790558\n",
      "    Val loss: 0.038185004144907\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.032006796449422836\n",
      "    Val loss: 0.0375383235514164\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.03636136278510094\n",
      "    Val loss: 0.08000471442937851\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.03717182204127312\n",
      "    Val loss: 0.0699826180934906\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.036910004913806915\n",
      "    Val loss: 0.03996257856488228\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.03427920863032341\n",
      "    Val loss: 0.041800569742918015\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.02989099733531475\n",
      "    Val loss: 0.0422702394425869\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.031233735382556915\n",
      "    Val loss: 0.0330667570233345\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.03760899603366852\n",
      "    Val loss: 0.034853722900152206\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.04064136743545532\n",
      "    Val loss: 0.05185838043689728\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.03305438905954361\n",
      "    Val loss: 0.08183607459068298\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.03251488879323006\n",
      "    Val loss: 0.056236572563648224\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.03082362748682499\n",
      "    Val loss: 0.06988393515348434\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.03619803860783577\n",
      "    Val loss: 0.05116322264075279\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.030759049579501152\n",
      "    Val loss: 0.04868154600262642\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.028812851756811142\n",
      "    Val loss: 0.033930640667676926\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.0314205028116703\n",
      "    Val loss: 0.04389990121126175\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.03126618266105652\n",
      "    Val loss: 0.04630417004227638\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.029346967115998268\n",
      "    Val loss: 0.042314279824495316\n",
      "\n",
      "Learning rate: [0.00023999999999999998]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.03901265189051628\n",
      "    Val loss: 0.036830317229032516\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.030286917462944984\n",
      "    Val loss: 0.04061107710003853\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.030279913917183876\n",
      "    Val loss: 0.0440167561173439\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.02853192202746868\n",
      "    Val loss: 0.04182528704404831\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 0.028322694823145866\n",
      "    Val loss: 0.04452044889330864\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 0.030486885458230972\n",
      "    Val loss: 0.05870134010910988\n",
      "\n",
      "Learning rate: [0.000192]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 0.02939341589808464\n",
      "    Val loss: 0.058024000376462936\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 0.026692762970924377\n",
      "    Val loss: 0.06136070564389229\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 0.02870827727019787\n",
      "    Val loss: 0.032012104988098145\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 0.032804083079099655\n",
      "    Val loss: 0.03274305909872055\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 0.03217237442731857\n",
      "    Val loss: 0.04940277710556984\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 0.02656632848083973\n",
      "    Val loss: 0.06767023354768753\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 0.02814462222158909\n",
      "    Val loss: 0.03231462463736534\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 0.027505168691277504\n",
      "    Val loss: 0.05239463225007057\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 0.03233432397246361\n",
      "    Val loss: 0.03177498281002045\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 0.030460022389888763\n",
      "    Val loss: 0.04817388206720352\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 0.02804102748632431\n",
      "    Val loss: 0.03749190643429756\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 0.028187749907374382\n",
      "    Val loss: 0.0532519556581974\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 0.02908230759203434\n",
      "    Val loss: 0.0411989688873291\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 0.030835339799523354\n",
      "    Val loss: 0.04535216838121414\n",
      "\n",
      "Learning rate: [0.00015360000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 0.028896547853946686\n",
      "    Val loss: 0.04674825072288513\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 0.02642769180238247\n",
      "    Val loss: 0.045998334884643555\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 0.03177496790885925\n",
      "    Val loss: 0.046903789043426514\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 0.02683589793741703\n",
      "    Val loss: 0.05254700034856796\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 0.028083138167858124\n",
      "    Val loss: 0.04548563063144684\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 0.028883274644613266\n",
      "    Val loss: 0.04121054708957672\n",
      "\n",
      "Learning rate: [0.00012288000000000002]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 0.026650121435523033\n",
      "    Val loss: 0.061007291078567505\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 0.027073943987488747\n",
      "    Val loss: 0.03509818762540817\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 0.02755538560450077\n",
      "    Val loss: 0.044519271701574326\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 0.030481930822134018\n",
      "    Val loss: 0.03753839060664177\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 0.027615133672952652\n",
      "    Val loss: 0.06243199482560158\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 0.02785658836364746\n",
      "    Val loss: 0.031949013471603394\n",
      "\n",
      "Learning rate: [9.830400000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 0.027610620483756065\n",
      "    Val loss: 0.05448554828763008\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 0.026551101356744766\n",
      "    Val loss: 0.04047713056206703\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 0.027097759768366814\n",
      "    Val loss: 0.0426039919257164\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 0.028177108615636826\n",
      "    Val loss: 0.08213604241609573\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 0.02893304079771042\n",
      "    Val loss: 0.05468263104557991\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 0.026417460292577744\n",
      "    Val loss: 0.052706483751535416\n",
      "\n",
      "Learning rate: [7.864320000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 0.027759630233049393\n",
      "    Val loss: 0.05024464428424835\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 0.02670692838728428\n",
      "    Val loss: 0.03959863632917404\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 0.027885273098945618\n",
      "    Val loss: 0.040063824504613876\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 0.02697169966995716\n",
      "    Val loss: 0.049010686576366425\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 0.026526665315032005\n",
      "    Val loss: 0.05165056511759758\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 0.02606843039393425\n",
      "    Val loss: 0.04896550625562668\n",
      "\n",
      "Learning rate: [6.291456000000001e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 0.02669563516974449\n",
      "    Val loss: 0.05859069898724556\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 0.02573160082101822\n",
      "    Val loss: 0.04529744014143944\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 0.0261834803968668\n",
      "    Val loss: 0.05184636637568474\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 0.025458939373493195\n",
      "    Val loss: 0.04923194274306297\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 0.026153983548283577\n",
      "    Val loss: 0.06763949990272522\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 0.025998814031481743\n",
      "    Val loss: 0.0457242876291275\n",
      "\n",
      "Learning rate: [5.0331648000000016e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 0.02561376243829727\n",
      "    Val loss: 0.03597234934568405\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 0.025930743664503098\n",
      "    Val loss: 0.04644016548991203\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 0.025498243048787117\n",
      "    Val loss: 0.033846527338027954\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 0.025797132402658463\n",
      "    Val loss: 0.04952384904026985\n",
      "\n",
      "Learning rate: [4.026531840000002e-05]\n",
      "Peak GPU memory usage:  2.21 GB\n",
      "Training completed.\n",
      "finished: det_bkg, 32000\n"
     ]
    }
   ],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model = models.Deep_Sets_Model()\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "\n",
    "    dataset_train = data.Dataset(dset_name, level, \"train\", num_signal_per_set=num_signal)\n",
    "    dataset_val = data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal)\n",
    "    \n",
    "    models.train(\n",
    "        model,\n",
    "        model_name,\n",
    "        loss_fn,\n",
    "        dataset_train,\n",
    "        dataset_val,\n",
    "        device,\n",
    "        lr,\n",
    "        lr_reduce_factor,\n",
    "        lr_reduce_patience,\n",
    "        batch_sizes[num_signal],\n",
    "        batch_sizes[num_signal],\n",
    "        epochs,\n",
    "        epochs_checkpoint\n",
    "    )\n",
    "\n",
    "    print(f\"finished: {level}, {num_signal}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd7d67",
   "metadata": {},
   "source": [
    "Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e6141",
   "metadata": {},
   "source": [
    "Linearity and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0440957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: gen, 8000\n",
      "finished: gen, 16000\n",
      "finished: gen, 32000\n",
      "finished: det, 8000\n",
      "finished: det, 16000\n",
      "finished: det, 32000\n",
      "finished: det_bkg, 8000\n",
      "finished: det_bkg, 16000\n",
      "finished: det_bkg, 32000\n"
     ]
    }
   ],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "    model = models.Deep_Sets_Model()\n",
    "    model.load_state_dict(models.open_model_state_dict(model_name))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_val = data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal)\n",
    "    \n",
    "    preds = models.predict_values_set_model(model, dataset_val.features, device)\n",
    "\n",
    "    results_lin = models.run_linearity_test(preds, dataset_val.labels)\n",
    "    results_err = models.run_error_test(preds, dataset_val.labels)\n",
    "\n",
    "    models.save_test_result(results_lin, \"lin\", num_signal, model_name)\n",
    "    models.save_test_result(results_err, \"err\", num_signal, model_name)\n",
    "\n",
    "    print(f\"finished: {level}, {num_signal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478c6e2",
   "metadata": {},
   "source": [
    "Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49049ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "    model = models.Deep_Sets_Model()\n",
    "    model.load_state_dict(models.open_model_state_dict(model_name))\n",
    "\n",
    "    dataset_val_sens = data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal, sensitivity=True)\n",
    "\n",
    "    preds = models.predict_values_set_model(model, dataset_val_sens.features, device)\n",
    "\n",
    "    results_sens = models.run_sensitivity_test(preds, dataset_val_sens.labels)\n",
    "\n",
    "    models.save_test_result(results_sens, \"sens\", num_signal, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61676683",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becef7ed",
   "metadata": {},
   "source": [
    "Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0ba234",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "fancy_level_names = {\n",
    "    \"gen\": \"Generator\", \n",
    "    \"det\" : \"Detector\", \n",
    "    \"det_bkg\" : \"Detector and Bkg.\"\n",
    "}\n",
    "\n",
    "for (level, num_signal), ax in zip(product(levels, num_signal_per_set), axs.flat):\n",
    "    \n",
    "    model_name = make_model_name(level, num_signal)\n",
    "\n",
    "    result = models.open_test_result(\"lin\", num_signal, model_name)\n",
    "\n",
    "    plot.plot_linearity(result, ax=ax)\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {fancy_level_names[level]}\"\n",
    "        f\"\\nEvents/set: {num_signal}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{num_sets_per_label[num_signal]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "fig.suptitle(f\"Deep Sets\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Path(\"plots\").joinpath(\"deep_sets_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
