{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5295639e",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ec52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product \n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb977a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"train\", \"val\"]\n",
    "levels = [\"gen\", \"det\", \"det_bkg\"]\n",
    "\n",
    "dset_name = \"sets_unbinned\"\n",
    "\n",
    "def make_model_name(level, num_signal): return f\"deep_sets_{level}_{num_signal}\"\n",
    "\n",
    "dc9_new_phys = -0.82\n",
    "\n",
    "num_signal_per_set = [8_000, 16_000, 32_000]\n",
    "num_sets_per_label = {8_000 : 400, 16_000: 200, 32_000 : 100} \n",
    "num_sets_sensitivity = 2_000\n",
    "bkg_signal_ratio = 0.79\n",
    "charge_bkg_fraction = 0.57\n",
    "\n",
    "device = helpers.models.select_device()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr = 3e-4\n",
    "lr_reduce_factor = 0.8\n",
    "lr_reduce_patience = 3\n",
    "batch_sizes = {8_000 : 32, 16_000 : 64, 32_000 : 128}\n",
    "epochs = 100\n",
    "epochs_checkpoint = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c05299",
   "metadata": {},
   "source": [
    "Save standard scaling constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56430e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "\n",
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "        sets_features, sets_labels = helpers.data.make_sets(\n",
    "            level,\n",
    "            split,\n",
    "            num_signal,\n",
    "            num_sets_per_label[num_signal],\n",
    "            bkg_signal_ratio=bkg_signal_ratio,\n",
    "            charge_bkg_fraction=charge_bkg_fraction\n",
    "        )\n",
    "\n",
    "        std_scale_mean = torch.mean(sets_features, dim=(0,1))\n",
    "        std_scale_std = torch.std(sets_features, dim=(0,1))\n",
    "\n",
    "        helpers.data.save_dset_file(std_scale_mean, dset_name, level, split, \"mean\", num_signal_per_set=num_signal)\n",
    "        helpers.data.save_dset_file(std_scale_std, dset_name, level, split, \"std\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a28e6b",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608053b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal, split in product(levels, num_signal_per_set, splits): \n",
    "\n",
    "    sets_features, sets_labels = helpers.data.make_sets(\n",
    "        level,\n",
    "        split,\n",
    "        num_signal,\n",
    "        num_sets_per_label[num_signal],\n",
    "        bkg_signal_ratio=bkg_signal_ratio,\n",
    "        charge_bkg_fraction=charge_bkg_fraction\n",
    "    )\n",
    "\n",
    "    sets_features = helpers.data.apply_std_scale(sets_features, dset_name, level, num_signal_per_set=num_signal)\n",
    "\n",
    "    helpers.data.save_dset_file(sets_features, dset_name, level, split, \"features\", num_signal_per_set=num_signal)\n",
    "    helpers.data.save_dset_file(sets_labels, dset_name, level, split, \"labels\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027bf5a",
   "metadata": {},
   "source": [
    "Sensitivity datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ece01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "\n",
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    sets_features, sets_labels = helpers.data.make_sets(\n",
    "        level,\n",
    "        split,\n",
    "        num_signal,\n",
    "        num_sets_sensitivity,\n",
    "        label_subset=[dc9_new_phys],\n",
    "        bkg_signal_ratio=bkg_signal_ratio,\n",
    "        charge_bkg_fraction=charge_bkg_fraction\n",
    "    )\n",
    "\n",
    "    sets_features = helpers.data.apply_std_scale(sets_features, dset_name, level, num_signal_per_set=num_signal)\n",
    "\n",
    "    helpers.data.save_dset_file(sets_features, dset_name, level, split, \"sens_features\", num_signal_per_set=num_signal)\n",
    "    helpers.data.save_dset_file(sets_labels, dset_name, level, split, \"sens_labels\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635b6e5",
   "metadata": {},
   "source": [
    "Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aaf298",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model = helpers.models.Deep_Sets_Model()\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "\n",
    "    dataset_train = helpers.data.Dataset(dset_name, level, \"train\", num_signal_per_set=num_signal)\n",
    "    dataset_val = helpers.data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal)\n",
    "    \n",
    "    helpers.models.train(\n",
    "        model,\n",
    "        model_name,\n",
    "        loss_fn,\n",
    "        dataset_train,\n",
    "        dataset_val,\n",
    "        device,\n",
    "        lr,\n",
    "        lr_reduce_factor,\n",
    "        lr_reduce_patience,\n",
    "        batch_sizes[num_signal],\n",
    "        batch_sizes[num_signal],\n",
    "        epochs,\n",
    "        epochs_checkpoint\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd7d67",
   "metadata": {},
   "source": [
    "Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e6141",
   "metadata": {},
   "source": [
    "Linearity and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0440957",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "    model = helpers.models.Deep_Sets_Model()\n",
    "    model.load_state_dict(helpers.models.open_model_state_dict(model_name))\n",
    "    \n",
    "    dataset_val = helpers.data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal)\n",
    "    \n",
    "    preds = helpers.models.predict_values_set_model(model, dataset_val.features, device)\n",
    "\n",
    "    results_lin = helpers.models.run_linearity_test(preds, dataset_val.labels)\n",
    "    results_err = helpers.models.run_error_test(preds, dataset_val.labels)\n",
    "\n",
    "    helpers.models.save_test_result(results_lin, \"lin\", num_signal, model_name)\n",
    "    helpers.models.save_test_result(results_err, \"err\", num_signal, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478c6e2",
   "metadata": {},
   "source": [
    "Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49049ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "    model = helpers.models.Deep_Sets_Model()\n",
    "    model.load_state_dict(helpers.models.open_model_state_dict(model_name))\n",
    "\n",
    "    dataset_val_sens = helpers.data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal, sensitivity=True)\n",
    "\n",
    "    preds = helpers.models.predict_values_set_model(model, dataset_val_sens.features, device)\n",
    "\n",
    "    results_sens = helpers.models.run_sensitivity_test(preds, dataset_val_sens.labels)\n",
    "\n",
    "    helpers.models.save_test_result(results_sens, \"sens\", num_signal, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61676683",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becef7ed",
   "metadata": {},
   "source": [
    "Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ba234",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "fancy_level_names = {\n",
    "    \"gen\": \"Generator\", \n",
    "    \"det\" : \"Detector\", \n",
    "    \"det_bkg\" : \"Detector and Bkg.\"\n",
    "}\n",
    "\n",
    "for (level, num_signal), ax in zip(product(levels, num_signal_per_set), axs.flat):\n",
    "    \n",
    "    model_name = make_model_name(level, num_signal)\n",
    "\n",
    "    result = helpers.models.open_test_result(\"lin\", num_signal, model_name)\n",
    "\n",
    "    helpers.plot.plot_linearity(result, ax=ax)\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {fancy_level_names[level]}\"\n",
    "        f\"\\nEvents/set: {num_signal}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{num_sets_per_label[num_signal]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "fig.suptitle(f\"Deep Sets\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Path(\"plots\").joinpath(\"deep_sets_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
