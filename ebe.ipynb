{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2803825",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772508a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c369b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"train\", \"val\"]\n",
    "levels = [\"gen\", \"det\"]\n",
    "\n",
    "bin_map = helpers.data.open_bin_map_file()\n",
    "\n",
    "dset_events_name = \"events_binned\"\n",
    "dset_sets_name = \"sets_binned\"\n",
    "\n",
    "def make_model_name(level): return f\"ebe_{level}\" \n",
    "\n",
    "dc9_new_phys = -0.82\n",
    "\n",
    "num_signal_per_set = [8_000, 16_000, 32_000]\n",
    "num_sets_per_label = {8_000 : 400, 16_000: 200, 32_000 : 100} \n",
    "num_sets_sensitivity = 2_000\n",
    "\n",
    "device = helpers.models.select_device()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr = 4e-3\n",
    "lr_reduce_factor = 0.95\n",
    "lr_reduce_patience = 0\n",
    "batch_size = 10_000\n",
    "epochs = 300\n",
    "epochs_checkpoint = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100f26a",
   "metadata": {},
   "source": [
    "Save standard scaling constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "\n",
    "for level in levels:\n",
    "\n",
    "    features, _ = helpers.data.make_events(level, split)\n",
    "    \n",
    "    std_scale_mean = torch.mean(features, dim=0) # check\n",
    "    std_scale_std = torch.std(features, dim=0)\n",
    "\n",
    "    helpers.data.save_dset_file(std_scale_mean, dset_events_name, level, split, \"mean\")\n",
    "    helpers.data.save_dset_file(std_scale_std, dset_events_name, level, split, \"std\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb6ef7",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c067390",
   "metadata": {},
   "source": [
    "Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, split in product(levels, splits): \n",
    "\n",
    "    features, labels = helpers.data.make_events(level, split)\n",
    "\n",
    "    features = helpers.data.apply_std_scale(features, dset_events_name, level)\n",
    "\n",
    "    helpers.data.save_dset_file(features, dset_events_name, level, split, \"features\")\n",
    "    helpers.data.save_dset_file(labels, dset_events_name, level, split, \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ee00e",
   "metadata": {},
   "source": [
    "Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f466a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "binned_labels = True\n",
    "\n",
    "for level, num_signal in product(levels, num_signal_per_set): \n",
    "\n",
    "    sets_features, sets_labels = helpers.data.make_sets(\n",
    "        level,\n",
    "        split,\n",
    "        num_signal,\n",
    "        num_sets_per_label[num_signal],\n",
    "        binned_labels=binned_labels\n",
    "    )\n",
    "\n",
    "    sets_features = helpers.data.apply_std_scale(sets_features, dset_events_name, level)\n",
    "\n",
    "    helpers.data.save_dset_file(sets_features, dset_sets_name, level, split, \"features\", num_signal_per_set=num_signal)\n",
    "    helpers.data.save_dset_file(sets_labels, dset_sets_name, level, split, \"labels\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72562a19",
   "metadata": {},
   "source": [
    "Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2aa9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "binned_labels = True\n",
    "\n",
    "for level, num_signal in product(levels, num_signal_per_set): \n",
    "\n",
    "    sets_features, sets_labels = helpers.data.make_sets(\n",
    "        level,\n",
    "        split,\n",
    "        num_signal,\n",
    "        num_sets_sensitivity,\n",
    "        binned_labels=binned_labels,\n",
    "        label_subset=[numpy.argwhere(bin_map==dc9_new_phys).item()]\n",
    "    )\n",
    "\n",
    "    sets_features = helpers.data.apply_std_scale(sets_features, dset_events_name, level)\n",
    "\n",
    "    helpers.data.save_dset_file(sets_features, dset_sets_name, level, split, \"sens_features\", num_signal_per_set=num_signal)\n",
    "    helpers.data.save_dset_file(sets_labels, dset_sets_name, level, split, \"sens_labels\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38249c6",
   "metadata": {},
   "source": [
    "Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in levels:\n",
    "\n",
    "    model = helpers.models.Event_by_Event_Model()\n",
    "\n",
    "    model_name = f\"ebe_{level}\"\n",
    "\n",
    "    dataset_train = helpers.data.Dataset(dset_events_name, level, \"train\")\n",
    "    dataset_val = helpers.data.Dataset(dset_events_name, level, \"val\")\n",
    "    \n",
    "    helpers.models.train(\n",
    "        model,\n",
    "        model_name,\n",
    "        loss_fn,\n",
    "        dataset_train,\n",
    "        dataset_val,\n",
    "        device,\n",
    "        lr,\n",
    "        lr_reduce_factor,\n",
    "        lr_reduce_patience,\n",
    "        batch_size,\n",
    "        batch_size,\n",
    "        epochs,\n",
    "        epochs_checkpoint\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ce5af",
   "metadata": {},
   "source": [
    "Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6dbea2",
   "metadata": {},
   "source": [
    "Linearity and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00646701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model_name = make_model_name(level)\n",
    "    model = helpers.models.Event_by_Event_Model()\n",
    "    model.load_state_dict(helpers.models.open_model_state_dict(model_name))\n",
    "\n",
    "    dataset_val = helpers.data.Dataset(dset_sets_name, level, \"val\", num_signal_per_set=num_signal)\n",
    "    \n",
    "    log_probs = helpers.models.predict_log_probs_event_model(model, dataset_val.features, device)\n",
    "    preds = helpers.models.predict_values_event_model(log_probs, bin_map, device)\n",
    "\n",
    "    results_lin = helpers.models.run_linearity_test(preds, dataset_val.labels)\n",
    "    results_err = helpers.models.run_error_test(preds, dataset_val.labels)\n",
    "\n",
    "    helpers.models.save_test_result(results_lin, \"lin\", num_signal, model_name)\n",
    "    helpers.models.save_test_result(results_err, \"err\", num_signal, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af8f5cb",
   "metadata": {},
   "source": [
    "Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model_name = make_model_name(level)\n",
    "    model = helpers.models.Event_by_Event_Model()\n",
    "    model.load_state_dict(helpers.models.open_model_state_dict(model_name))\n",
    "\n",
    "    dataset_val_sens = helpers.data.Dataset(dset_sets_name, level, \"val\", num_signal_per_set=num_signal, sensitivity=True)\n",
    "\n",
    "    log_probs = helpers.models.predict_log_probs_event_model(model, dataset_val_sens.features, device)\n",
    "    preds = helpers.models.predict_values_event_model(log_probs, bin_map, device)\n",
    "\n",
    "    results_sens = helpers.models.run_sensitivity_test(preds, dataset_val_sens.labels)\n",
    "\n",
    "    model_name = make_model_name(level)\n",
    "    helpers.models.save_test_result(results_sens, \"sens\", num_signal, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b7b81",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf655b",
   "metadata": {},
   "source": [
    "Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88335cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "fancy_level_names = {\n",
    "    \"gen\": \"Generator\", \n",
    "    \"det\" : \"Detector\", \n",
    "}\n",
    "\n",
    "for (level, num_signal), ax in zip(product(levels, num_signal_per_set), axs.flat):\n",
    "    \n",
    "    model_name = make_model_name(level)\n",
    "\n",
    "    result = helpers.models.open_test_result(\"lin\", num_signal, model_name)\n",
    "\n",
    "    helpers.plot.plot_linearity(result, ax=ax)\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {fancy_level_names[level]}\"\n",
    "        f\"\\nEvents/set: {num_signal}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{num_sets_per_label[num_signal]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "fig.suptitle(f\"Deep Sets\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Path(\"plots\").joinpath(\"deep_sets_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
