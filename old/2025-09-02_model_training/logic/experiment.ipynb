{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$B \\rightarrow K^* \\ell \\ell$  machine learning experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers.datasets.make_and_save.aggregated_signal import Aggregated_Signal_Dataframe_Handler\n",
    "from helpers.datasets.constants import Names_of_Levels, Names_of_q_Squared_Vetos, Raw_Signal_Trial_Ranges, Numbers_of_Events_per_Set, Names_of_Splits, Names_of_Labels\n",
    "from helpers.experiment.experiment import CNN_Group, Deep_Sets_Group, Event_by_Event_Group\n",
    "from helpers.experiment.results_table import Results_Table\n",
    "from helpers.experiment.constants import Paths_to_Directories, delta_C9_value_new_physics, delta_C9_value_standard_model\n",
    "from helpers.models.hardware_util import select_device\n",
    "from helpers.experiment.experiment import evaluate_model\n",
    "from helpers.datasets.settings.settings import Binned_Sets_Dataset_Settings\n",
    "from helpers.datasets.datasets import Unbinned_Sets_Dataset, Binned_Sets_Dataset, Images_Dataset\n",
    "from helpers.datasets.make_and_save.preprocessing import apply_q_squared_veto\n",
    "\n",
    "from helpers.plot.linearity import plot_linearity\n",
    "from helpers.plot.probabilities import plot_log_probability_distribution_examples\n",
    "\n",
    "results_table = Results_Table()\n",
    "device = select_device()\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "mpl.rcParams[\"figure.dpi\"] = 400\n",
    "mpl.rcParams[\"axes.titlesize\"] = 8\n",
    "mpl.rcParams[\"figure.titlesize\"] = 8\n",
    "mpl.rcParams[\"figure.labelsize\"] = 30\n",
    "mpl.rcParams[\"text.usetex\"] = True\n",
    "mpl.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{bm}\"\n",
    "mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "mpl.rcParams[\"font.serif\"] = [\"Computer Modern\"]\n",
    "mpl.rcParams[\"font.size\"] = 8\n",
    "mpl.rcParams[\"axes.titley\"] = None\n",
    "mpl.rcParams[\"axes.titlepad\"] = 2\n",
    "mpl.rcParams[\"legend.fancybox\"] = False\n",
    "mpl.rcParams[\"legend.framealpha\"] = 0\n",
    "mpl.rcParams[\"legend.markerscale\"] = 1\n",
    "mpl.rcParams[\"legend.fontsize\"] = 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remake aggregated signal dataframe files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in (Names_of_Levels().generator, Names_of_Levels().detector):\n",
    "    for trial_range in Raw_Signal_Trial_Ranges().tuple_:\n",
    "        \n",
    "        Aggregated_Signal_Dataframe_Handler(\n",
    "            path_to_main_datasets_dir=Paths_to_Directories().path_to_main_datasets_dir,\n",
    "            level=level,\n",
    "            trial_range=trial_range\n",
    "        ).make_and_save(Paths_to_Directories().path_to_raw_signal_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_sets_group = Deep_Sets_Group(\n",
    "    num_sets_per_label={6_000 : 583, 24_000 : 145, 70_000 : 50},\n",
    "    num_sets_per_label_sensitivity=2_000,\n",
    "    q_squared_veto=Names_of_q_Squared_Vetos().resonances,\n",
    "    std_scale=True,\n",
    "    shuffle=True,\n",
    "    uniform_label_counts=True,\n",
    "    loss_fn=MSELoss(),\n",
    "    learning_rate=3e-4,\n",
    "    learning_rate_scheduler_reduction_factor=0.97,\n",
    "    size_of_training_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    size_of_evaluation_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    number_of_epochs=100,\n",
    "    number_of_epochs_between_checkpoints=1,\n",
    "    results_table=results_table,\n",
    "    device=device,\n",
    "    bkg_fraction=0.44,\n",
    "    bkg_charge_fraction=0.57\n",
    ")\n",
    "\n",
    "# deep_sets_group.train_all(remake_datasets=True)\n",
    "\n",
    "# deep_sets_group.train_subset([Names_of_Levels().detector_and_background], [6_000, 24_000, 70_000], remake_datasets=True)\n",
    "\n",
    "deep_sets_group.evaluate_all(remake_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "levels = Names_of_Levels().tuple_\n",
    "names_of_levels = {\n",
    "    Names_of_Levels().generator : \"Generator\", \n",
    "    Names_of_Levels().detector : \"Detector\", \n",
    "    Names_of_Levels().detector_and_background : \"Detector and Bkg.\"\n",
    "}\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    plot_linearity(\n",
    "        linearity_test_results=deep_sets_group.results[level][num_events_per_set].linearity_results, \n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {names_of_levels[level]}\"\n",
    "        f\"\\nEvents/set: {num_events_per_set}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{deep_sets_group.get_individual(level=level, num_events_per_set=num_events_per_set).evaluation_dataset_settings.set.num_sets_per_label}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "fig.suptitle(f\"Deep sets\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"deep_sets_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\70000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\70000_eval_sens_labels.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNN_Model_Logic_Shawn:\n\tMissing key(s) in state_dict: \"convolution_layers.1.weight\", \"convolution_layers.1.bias\", \"convolution_layers.1.running_mean\", \"convolution_layers.1.running_var\", \"convolution_layers.4.convolution_block.1.weight\", \"convolution_layers.4.convolution_block.1.bias\", \"convolution_layers.4.convolution_block.1.running_mean\", \"convolution_layers.4.convolution_block.1.running_var\", \"convolution_layers.4.convolution_block.3.weight\", \"convolution_layers.4.convolution_block.3.bias\", \"convolution_layers.4.convolution_block.4.weight\", \"convolution_layers.4.convolution_block.4.bias\", \"convolution_layers.4.convolution_block.4.running_mean\", \"convolution_layers.4.convolution_block.4.running_var\", \"convolution_layers.5.convolution_block.1.weight\", \"convolution_layers.5.convolution_block.1.bias\", \"convolution_layers.5.convolution_block.1.running_mean\", \"convolution_layers.5.convolution_block.1.running_var\", \"convolution_layers.5.convolution_block.3.weight\", \"convolution_layers.5.convolution_block.3.bias\", \"convolution_layers.5.convolution_block.4.weight\", \"convolution_layers.5.convolution_block.4.bias\", \"convolution_layers.5.convolution_block.4.running_mean\", \"convolution_layers.5.convolution_block.4.running_var\", \"convolution_layers.6.convolution_block.1.weight\", \"convolution_layers.6.convolution_block.1.bias\", \"convolution_layers.6.convolution_block.1.running_mean\", \"convolution_layers.6.convolution_block.1.running_var\", \"convolution_layers.6.convolution_block.3.weight\", \"convolution_layers.6.convolution_block.3.bias\", \"convolution_layers.6.convolution_block.4.weight\", \"convolution_layers.6.convolution_block.4.bias\", \"convolution_layers.6.convolution_block.4.running_mean\", \"convolution_layers.6.convolution_block.4.running_var\", \"convolution_layers.7.convolution_block_a.0.weight\", \"convolution_layers.7.convolution_block_a.0.bias\", \"convolution_layers.7.convolution_block_a.1.weight\", \"convolution_layers.7.convolution_block_a.1.bias\", \"convolution_layers.7.convolution_block_a.1.running_mean\", \"convolution_layers.7.convolution_block_a.1.running_var\", \"convolution_layers.7.convolution_block_a.3.weight\", \"convolution_layers.7.convolution_block_a.3.bias\", \"convolution_layers.7.convolution_block_a.4.weight\", \"convolution_layers.7.convolution_block_a.4.bias\", \"convolution_layers.7.convolution_block_a.4.running_mean\", \"convolution_layers.7.convolution_block_a.4.running_var\", \"convolution_layers.7.convolution_block_b.0.weight\", \"convolution_layers.7.convolution_block_b.0.bias\", \"convolution_layers.7.convolution_block_b.1.weight\", \"convolution_layers.7.convolution_block_b.1.bias\", \"convolution_layers.7.convolution_block_b.1.running_mean\", \"convolution_layers.7.convolution_block_b.1.running_var\", \"convolution_layers.8.convolution_block.1.weight\", \"convolution_layers.8.convolution_block.1.bias\", \"convolution_layers.8.convolution_block.1.running_mean\", \"convolution_layers.8.convolution_block.1.running_var\", \"convolution_layers.8.convolution_block.3.weight\", \"convolution_layers.8.convolution_block.3.bias\", \"convolution_layers.8.convolution_block.4.weight\", \"convolution_layers.8.convolution_block.4.bias\", \"convolution_layers.8.convolution_block.4.running_mean\", \"convolution_layers.8.convolution_block.4.running_var\", \"convolution_layers.9.convolution_block.1.weight\", \"convolution_layers.9.convolution_block.1.bias\", \"convolution_layers.9.convolution_block.1.running_mean\", \"convolution_layers.9.convolution_block.1.running_var\", \"convolution_layers.9.convolution_block.3.weight\", \"convolution_layers.9.convolution_block.3.bias\", \"convolution_layers.9.convolution_block.4.weight\", \"convolution_layers.9.convolution_block.4.bias\", \"convolution_layers.9.convolution_block.4.running_mean\", \"convolution_layers.9.convolution_block.4.running_var\", \"convolution_layers.10.convolution_block.1.weight\", \"convolution_layers.10.convolution_block.1.bias\", \"convolution_layers.10.convolution_block.1.running_mean\", \"convolution_layers.10.convolution_block.1.running_var\", \"convolution_layers.10.convolution_block.3.weight\", \"convolution_layers.10.convolution_block.3.bias\", \"convolution_layers.10.convolution_block.4.weight\", \"convolution_layers.10.convolution_block.4.bias\", \"convolution_layers.10.convolution_block.4.running_mean\", \"convolution_layers.10.convolution_block.4.running_var\", \"convolution_layers.11.convolution_block_a.0.weight\", \"convolution_layers.11.convolution_block_a.0.bias\", \"convolution_layers.11.convolution_block_a.1.weight\", \"convolution_layers.11.convolution_block_a.1.bias\", \"convolution_layers.11.convolution_block_a.1.running_mean\", \"convolution_layers.11.convolution_block_a.1.running_var\", \"convolution_layers.11.convolution_block_a.3.weight\", \"convolution_layers.11.convolution_block_a.3.bias\", \"convolution_layers.11.convolution_block_a.4.weight\", \"convolution_layers.11.convolution_block_a.4.bias\", \"convolution_layers.11.convolution_block_a.4.running_mean\", \"convolution_layers.11.convolution_block_a.4.running_var\", \"convolution_layers.11.convolution_block_b.0.weight\", \"convolution_layers.11.convolution_block_b.0.bias\", \"convolution_layers.11.convolution_block_b.1.weight\", \"convolution_layers.11.convolution_block_b.1.bias\", \"convolution_layers.11.convolution_block_b.1.running_mean\", \"convolution_layers.11.convolution_block_b.1.running_var\", \"convolution_layers.12.convolution_block.1.weight\", \"convolution_layers.12.convolution_block.1.bias\", \"convolution_layers.12.convolution_block.1.running_mean\", \"convolution_layers.12.convolution_block.1.running_var\", \"convolution_layers.12.convolution_block.3.weight\", \"convolution_layers.12.convolution_block.3.bias\", \"convolution_layers.12.convolution_block.4.weight\", \"convolution_layers.12.convolution_block.4.bias\", \"convolution_layers.12.convolution_block.4.running_mean\", \"convolution_layers.12.convolution_block.4.running_var\", \"convolution_layers.13.convolution_block.1.weight\", \"convolution_layers.13.convolution_block.1.bias\", \"convolution_layers.13.convolution_block.1.running_mean\", \"convolution_layers.13.convolution_block.1.running_var\", \"convolution_layers.13.convolution_block.3.weight\", \"convolution_layers.13.convolution_block.3.bias\", \"convolution_layers.13.convolution_block.4.weight\", \"convolution_layers.13.convolution_block.4.bias\", \"convolution_layers.13.convolution_block.4.running_mean\", \"convolution_layers.13.convolution_block.4.running_var\", \"convolution_layers.14.convolution_block.0.weight\", \"convolution_layers.14.convolution_block.0.bias\", \"convolution_layers.14.convolution_block.1.weight\", \"convolution_layers.14.convolution_block.1.bias\", \"convolution_layers.14.convolution_block.1.running_mean\", \"convolution_layers.14.convolution_block.1.running_var\", \"convolution_layers.14.convolution_block.3.weight\", \"convolution_layers.14.convolution_block.3.bias\", \"convolution_layers.14.convolution_block.4.weight\", \"convolution_layers.14.convolution_block.4.bias\", \"convolution_layers.14.convolution_block.4.running_mean\", \"convolution_layers.14.convolution_block.4.running_var\", \"convolution_layers.15.convolution_block.0.weight\", \"convolution_layers.15.convolution_block.0.bias\", \"convolution_layers.15.convolution_block.1.weight\", \"convolution_layers.15.convolution_block.1.bias\", \"convolution_layers.15.convolution_block.1.running_mean\", \"convolution_layers.15.convolution_block.1.running_var\", \"convolution_layers.15.convolution_block.3.weight\", \"convolution_layers.15.convolution_block.3.bias\", \"convolution_layers.15.convolution_block.4.weight\", \"convolution_layers.15.convolution_block.4.bias\", \"convolution_layers.15.convolution_block.4.running_mean\", \"convolution_layers.15.convolution_block.4.running_var\", \"convolution_layers.16.convolution_block.0.weight\", \"convolution_layers.16.convolution_block.0.bias\", \"convolution_layers.16.convolution_block.1.weight\", \"convolution_layers.16.convolution_block.1.bias\", \"convolution_layers.16.convolution_block.1.running_mean\", \"convolution_layers.16.convolution_block.1.running_var\", \"convolution_layers.16.convolution_block.3.weight\", \"convolution_layers.16.convolution_block.3.bias\", \"convolution_layers.16.convolution_block.4.weight\", \"convolution_layers.16.convolution_block.4.bias\", \"convolution_layers.16.convolution_block.4.running_mean\", \"convolution_layers.16.convolution_block.4.running_var\", \"convolution_layers.17.convolution_block_a.0.weight\", \"convolution_layers.17.convolution_block_a.0.bias\", \"convolution_layers.17.convolution_block_a.1.weight\", \"convolution_layers.17.convolution_block_a.1.bias\", \"convolution_layers.17.convolution_block_a.1.running_mean\", \"convolution_layers.17.convolution_block_a.1.running_var\", \"convolution_layers.17.convolution_block_a.3.weight\", \"convolution_layers.17.convolution_block_a.3.bias\", \"convolution_layers.17.convolution_block_a.4.weight\", \"convolution_layers.17.convolution_block_a.4.bias\", \"convolution_layers.17.convolution_block_a.4.running_mean\", \"convolution_layers.17.convolution_block_a.4.running_var\", \"convolution_layers.17.convolution_block_b.0.weight\", \"convolution_layers.17.convolution_block_b.0.bias\", \"convolution_layers.17.convolution_block_b.1.weight\", \"convolution_layers.17.convolution_block_b.1.bias\", \"convolution_layers.17.convolution_block_b.1.running_mean\", \"convolution_layers.17.convolution_block_b.1.running_var\", \"convolution_layers.18.convolution_block.0.weight\", \"convolution_layers.18.convolution_block.0.bias\", \"convolution_layers.18.convolution_block.1.weight\", \"convolution_layers.18.convolution_block.1.bias\", \"convolution_layers.18.convolution_block.1.running_mean\", \"convolution_layers.18.convolution_block.1.running_var\", \"convolution_layers.18.convolution_block.3.weight\", \"convolution_layers.18.convolution_block.3.bias\", \"convolution_layers.18.convolution_block.4.weight\", \"convolution_layers.18.convolution_block.4.bias\", \"convolution_layers.18.convolution_block.4.running_mean\", \"convolution_layers.18.convolution_block.4.running_var\", \"convolution_layers.19.convolution_block.0.weight\", \"convolution_layers.19.convolution_block.0.bias\", \"convolution_layers.19.convolution_block.1.weight\", \"convolution_layers.19.convolution_block.1.bias\", \"convolution_layers.19.convolution_block.1.running_mean\", \"convolution_layers.19.convolution_block.1.running_var\", \"convolution_layers.19.convolution_block.3.weight\", \"convolution_layers.19.convolution_block.3.bias\", \"convolution_layers.19.convolution_block.4.weight\", \"convolution_layers.19.convolution_block.4.bias\", \"convolution_layers.19.convolution_block.4.running_mean\", \"convolution_layers.19.convolution_block.4.running_var\", \"dense_layers.3.weight\", \"dense_layers.3.bias\". \n\tUnexpected key(s) in state_dict: \"convolution_layers.3.convolution_block.0.weight\", \"convolution_layers.3.convolution_block.0.bias\", \"convolution_layers.3.convolution_block.2.weight\", \"convolution_layers.3.convolution_block.2.bias\", \"convolution_layers.4.convolution_block.2.weight\", \"convolution_layers.4.convolution_block.2.bias\", \"convolution_layers.5.convolution_block.2.weight\", \"convolution_layers.5.convolution_block.2.bias\", \"convolution_layers.6.convolution.weight\", \"convolution_layers.6.convolution.bias\", \"convolution_layers.6.convolution_block.2.weight\", \"convolution_layers.6.convolution_block.2.bias\", \"convolution_layers.7.convolution_block.0.weight\", \"convolution_layers.7.convolution_block.0.bias\", \"convolution_layers.7.convolution_block.2.weight\", \"convolution_layers.7.convolution_block.2.bias\", \"convolution_layers.8.convolution_block.2.weight\", \"convolution_layers.8.convolution_block.2.bias\", \"convolution_layers.9.convolution_block.2.weight\", \"convolution_layers.9.convolution_block.2.bias\", \"convolution_layers.10.convolution.weight\", \"convolution_layers.10.convolution.bias\", \"convolution_layers.10.convolution_block.2.weight\", \"convolution_layers.10.convolution_block.2.bias\", \"convolution_layers.11.convolution_block.0.weight\", \"convolution_layers.11.convolution_block.0.bias\", \"convolution_layers.11.convolution_block.2.weight\", \"convolution_layers.11.convolution_block.2.bias\", \"convolution_layers.12.convolution_block.2.weight\", \"convolution_layers.12.convolution_block.2.bias\", \"convolution_layers.13.convolution_block.2.weight\", \"convolution_layers.13.convolution_block.2.bias\", \"dense_layers.2.weight\", \"dense_layers.2.bias\". \n\tsize mismatch for convolution_layers.0.weight: copying a param with shape torch.Size([16, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 1, 7, 7, 7]).\n\tsize mismatch for convolution_layers.4.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3, 3]).\n\tsize mismatch for convolution_layers.4.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for convolution_layers.5.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3, 3]).\n\tsize mismatch for convolution_layers.5.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for convolution_layers.6.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3, 3]).\n\tsize mismatch for convolution_layers.6.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for convolution_layers.8.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3, 3]).\n\tsize mismatch for convolution_layers.8.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for convolution_layers.9.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3, 3]).\n\tsize mismatch for convolution_layers.9.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for convolution_layers.10.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3, 3]).\n\tsize mismatch for convolution_layers.10.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for convolution_layers.12.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3, 3]).\n\tsize mismatch for convolution_layers.12.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for convolution_layers.13.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3, 3]).\n\tsize mismatch for convolution_layers.13.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for dense_layers.0.weight: copying a param with shape torch.Size([32, 16]) from checkpoint, the shape in current model is torch.Size([1000, 512]).\n\tsize mismatch for dense_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1000]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m      1\u001b[39m cnn_group = CNN_Group(\n\u001b[32m      2\u001b[39m     num_sets_per_label={\u001b[32m6_000\u001b[39m : \u001b[32m583\u001b[39m, \u001b[32m24_000\u001b[39m : \u001b[32m145\u001b[39m, \u001b[32m70_000\u001b[39m : \u001b[32m50\u001b[39m},\n\u001b[32m      3\u001b[39m     num_sets_per_label_sensitivity=\u001b[32m2_000\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     bkg_charge_fraction=\u001b[32m0.57\u001b[39m\n\u001b[32m     20\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# cnn_group.train_subset(levels=[Names_of_Levels().detector_and_background,], nums_events_per_set=(24_000,), remake_datasets=False)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mcnn_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremake_datasets\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\experiment\\experiment.py:980\u001b[39m, in \u001b[36mCNN_Group.evaluate_all\u001b[39m\u001b[34m(self, remake_datasets, epoch)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, remake_datasets, epoch=\u001b[33m\"\u001b[39m\u001b[33mfinal\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    978\u001b[39m     \u001b[38;5;28mself\u001b[39m.results = {\n\u001b[32m    979\u001b[39m         level : {\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m             num_events_per_set : \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_individual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_events_per_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_events_per_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremake_datasets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremake_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    981\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m num_events_per_set \u001b[38;5;129;01min\u001b[39;00m Numbers_of_Events_per_Set().tuple_\n\u001b[32m    982\u001b[39m         }\n\u001b[32m    983\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m Names_of_Levels().tuple_\n\u001b[32m    984\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\experiment\\experiment.py:436\u001b[39m, in \u001b[36mCNN.evaluate_model\u001b[39m\u001b[34m(self, remake_datasets, epoch)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[32m    434\u001b[39m     dataset.load()\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m results = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43msensitivity_evaluation_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msensitivity_evaluation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresults_table\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresults_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[32m    446\u001b[39m     dataset.unload()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\experiment\\experiment.py:125\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, evaluation_dataset, sensitivity_evaluation_dataset, results_table, device, epoch)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m log_probabilities\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch == \u001b[33m\"\u001b[39m\u001b[33mfinal\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_final_model_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(epoch) == \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    127\u001b[39m     model.load_checkpoint_model_file(epoch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\models\\models.py:21\u001b[39m, in \u001b[36mModel.load_final_model_from_file\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_final_model_from_file\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     20\u001b[39m     state_dict = \u001b[38;5;28mself\u001b[39m.file_handler.loader.load_saved_final_model_state_dict()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tetha\\miniforge3\\envs\\ml3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for CNN_Model_Logic_Shawn:\n\tMissing key(s) in state_dict: \"convolution_layers.1.weight\", \"convolution_layers.1.bias\", \"convolution_layers.1.running_mean\", \"convolution_layers.1.running_var\", \"convolution_layers.4.convolution_block.1.weight\", \"convolution_layers.4.convolution_block.1.bias\", \"convolution_layers.4.convolution_block.1.running_mean\", \"convolution_layers.4.convolution_block.1.running_var\", \"convolution_layers.4.convolution_block.3.weight\", \"convolution_layers.4.convolution_block.3.bias\", \"convolution_layers.4.convolution_block.4.weight\", \"convolution_layers.4.convolution_block.4.bias\", \"convolution_layers.4.convolution_block.4.running_mean\", \"convolution_layers.4.convolution_block.4.running_var\", \"convolution_layers.5.convolution_block.1.weight\", \"convolution_layers.5.convolution_block.1.bias\", \"convolution_layers.5.convolution_block.1.running_mean\", \"convolution_layers.5.convolution_block.1.running_var\", \"convolution_layers.5.convolution_block.3.weight\", \"convolution_layers.5.convolution_block.3.bias\", \"convolution_layers.5.convolution_block.4.weight\", \"convolution_layers.5.convolution_block.4.bias\", \"convolution_layers.5.convolution_block.4.running_mean\", \"convolution_layers.5.convolution_block.4.running_var\", \"convolution_layers.6.convolution_block.1.weight\", \"convolution_layers.6.convolution_block.1.bias\", \"convolution_layers.6.convolution_block.1.running_mean\", \"convolution_layers.6.convolution_block.1.running_var\", \"convolution_layers.6.convolution_block.3.weight\", \"convolution_layers.6.convolution_block.3.bias\", \"convolution_layers.6.convolution_block.4.weight\", \"convolution_layers.6.convolution_block.4.bias\", \"convolution_layers.6.convolution_block.4.running_mean\", \"convolution_layers.6.convolution_block.4.running_var\", \"convolution_layers.7.convolution_block_a.0.weight\", \"convolution_layers.7.convolution_block_a.0.bias\", \"convolution_layers.7.convolution_block_a.1.weight\", \"convolution_layers.7.convolution_block_a.1.bias\", \"convolution_layers.7.convolution_block_a.1.running_mean\", \"convolution_layers.7.convolution_block_a.1.running_var\", \"convolution_layers.7.convolution_block_a.3.weight\", \"convolution_layers.7.convolution_block_a.3.bias\", \"convolution_layers.7.convolution_block_a.4.weight\", \"convolution_layers.7.convolution_block_a.4.bias\", \"convolution_layers.7.convolution_block_a.4.running_mean\", \"convolution_layers.7.convolution_block_a.4.running_var\", \"convolution_layers.7.convolution_block_b.0.weight\", \"convolution_layers.7.convolution_block_b.0.bias\", \"convolution_layers.7.convolution_block_b.1.weight\", \"convolution_layers.7.convolution_block_b.1.bias\", \"convolution_layers.7.convolution_block_b.1.running_mean\", \"convolution_layers.7.convolution_block_b.1.running_var\", \"convolution_layers.8.convolution_block.1.weight\", \"convolution_layers.8.convolution_block.1.bias\", \"convolution_layers.8.convolution_block.1.running_mean\", \"convolution_layers.8.convolution_block.1.running_var\", \"convolution_layers.8.convolution_block.3.weight\", \"convolution_layers.8.convolution_block.3.bias\", \"convolution_layers.8.convolution_block.4.weight\", \"convolution_layers.8.convolution_block.4.bias\", \"convolution_layers.8.convolution_block.4.running_mean\", \"convolution_layers.8.convolution_block.4.running_var\", \"convolution_layers.9.convolution_block.1.weight\", \"convolution_layers.9.convolution_block.1.bias\", \"convolution_layers.9.convolution_block.1.running_mean\", \"convolution_layers.9.convolution_block.1.running_var\", \"convolution_layers.9.convolution_block.3.weight\", \"convolution_layers.9.convolution_block.3.bias\", \"convolution_layers.9.convolution_block.4.weight\", \"convolution_layers.9.convolution_block.4.bias\", \"convolution_layers.9.convolution_block.4.running_mean\", \"convolution_layers.9.convolution_block.4.running_var\", \"convolution_layers.10.convolution_block.1.weight\", \"convolution_layers.10.convolution_block.1.bias\", \"convolution_layers.10.convolution_block.1.running_mean\", \"convolution_layers.10.convolution_block.1.running_var\", \"convolution_layers.10.convolution_block.3.weight\", \"convolution_layers.10.convolution_block.3.bias\", \"convolution_layers.10.convolution_block.4.weight\", \"convolution_layers.10.convolution_block.4.bias\", \"convolution_layers.10.convolution_block.4.running_mean\", \"convolution_layers.10.convolution_block.4.running_var\", \"convolution_layers.11.convolution_block_a.0.weight\", \"convolution_layers.11.convolution_block_a.0.bias\", \"convolution_layers.11.convolution_block_a.1.weight\", \"convolution_layers.11.convolution_block_a.1.bias\", \"convolution_layers.11.convolution_block_a.1.running_mean\", \"convolution_layers.11.convolution_block_a.1.running_var\", \"convolution_layers.11.convolution_block_a.3.weight\", \"convolution_layers.11.convolution_block_a.3.bias\", \"convolution_layers.11.convolution_block_a.4.weight\", \"convolution_layers.11.convolution_block_a.4.bias\", \"convolution_layers.11.convolution_block_a.4.running_mean\", \"convolution_layers.11.convolution_block_a.4.running_var\", \"convolution_layers.11.convolution_block_b.0.weight\", \"convolution_layers.11.convolution_block_b.0.bias\", \"convolution_layers.11.convolution_block_b.1.weight\", \"convolution_layers.11.convolution_block_b.1.bias\", \"convolution_layers.11.convolution_block_b.1.running_mean\", \"convolution_layers.11.convolution_block_b.1.running_var\", \"convolution_layers.12.convolution_block.1.weight\", \"convolution_layers.12.convolution_block.1.bias\", \"convolution_layers.12.convolution_block.1.running_mean\", \"convolution_layers.12.convolution_block.1.running_var\", \"convolution_layers.12.convolution_block.3.weight\", \"convolution_layers.12.convolution_block.3.bias\", \"convolution_layers.12.convolution_block.4.weight\", \"convolution_layers.12.convolution_block.4.bias\", \"convolution_layers.12.convolution_block.4.running_mean\", \"convolution_layers.12.convolution_block.4.running_var\", \"convolution_layers.13.convolution_block.1.weight\", \"convolution_layers.13.convolution_block.1.bias\", \"convolution_layers.13.convolution_block.1.running_mean\", \"convolution_layers.13.convolution_block.1.running_var\", \"convolution_layers.13.convolution_block.3.weight\", \"convolution_layers.13.convolution_block.3.bias\", \"convolution_layers.13.convolution_block.4.weight\", \"convolution_layers.13.convolution_block.4.bias\", \"convolution_layers.13.convolution_block.4.running_mean\", \"convolution_layers.13.convolution_block.4.running_var\", \"convolution_layers.14.convolution_block.0.weight\", \"convolution_layers.14.convolution_block.0.bias\", \"convolution_layers.14.convolution_block.1.weight\", \"convolution_layers.14.convolution_block.1.bias\", \"convolution_layers.14.convolution_block.1.running_mean\", \"convolution_layers.14.convolution_block.1.running_var\", \"convolution_layers.14.convolution_block.3.weight\", \"convolution_layers.14.convolution_block.3.bias\", \"convolution_layers.14.convolution_block.4.weight\", \"convolution_layers.14.convolution_block.4.bias\", \"convolution_layers.14.convolution_block.4.running_mean\", \"convolution_layers.14.convolution_block.4.running_var\", \"convolution_layers.15.convolution_block.0.weight\", \"convolution_layers.15.convolution_block.0.bias\", \"convolution_layers.15.convolution_block.1.weight\", \"convolution_layers.15.convolution_block.1.bias\", \"convolution_layers.15.convolution_block.1.running_mean\", \"convolution_layers.15.convolution_block.1.running_var\", \"convolution_layers.15.convolution_block.3.weight\", \"convolution_layers.15.convolution_block.3.bias\", \"convolution_layers.15.convolution_block.4.weight\", \"convolution_layers.15.convolution_block.4.bias\", \"convolution_layers.15.convolution_block.4.running_mean\", \"convolution_layers.15.convolution_block.4.running_var\", \"convolution_layers.16.convolution_block.0.weight\", \"convolution_layers.16.convolution_block.0.bias\", \"convolution_layers.16.convolution_block.1.weight\", \"convolution_layers.16.convolution_block.1.bias\", \"convolution_layers.16.convolution_block.1.running_mean\", \"convolution_layers.16.convolution_block.1.running_var\", \"convolution_layers.16.convolution_block.3.weight\", \"convolution_layers.16.convolution_block.3.bias\", \"convolution_layers.16.convolution_block.4.weight\", \"convolution_layers.16.convolution_block.4.bias\", \"convolution_layers.16.convolution_block.4.running_mean\", \"convolution_layers.16.convolution_block.4.running_var\", \"convolution_layers.17.convolution_block_a.0.weight\", \"convolution_layers.17.convolution_block_a.0.bias\", \"convolution_layers.17.convolution_block_a.1.weight\", \"convolution_layers.17.convolution_block_a.1.bias\", \"convolution_layers.17.convolution_block_a.1.running_mean\", \"convolution_layers.17.convolution_block_a.1.running_var\", \"convolution_layers.17.convolution_block_a.3.weight\", \"convolution_layers.17.convolution_block_a.3.bias\", \"convolution_layers.17.convolution_block_a.4.weight\", \"convolution_layers.17.convolution_block_a.4.bias\", \"convolution_layers.17.convolution_block_a.4.running_mean\", \"convolution_layers.17.convolution_block_a.4.running_var\", \"convolution_layers.17.convolution_block_b.0.weight\", \"convolution_layers.17.convolution_block_b.0.bias\", \"convolution_layers.17.convolution_block_b.1.weight\", \"convolution_layers.17.convolution_block_b.1.bias\", \"convolution_layers.17.convolution_block_b.1.running_mean\", \"convolution_layers.17.convolution_block_b.1.running_var\", \"convolution_layers.18.convolution_block.0.weight\", \"convolution_layers.18.convolution_block.0.bias\", \"convolution_layers.18.convolution_block.1.weight\", \"convolution_layers.18.convolution_block.1.bias\", \"convolution_layers.18.convolution_block.1.running_mean\", \"convolution_layers.18.convolution_block.1.running_var\", \"convolution_layers.18.convolution_block.3.weight\", \"convolution_layers.18.convolution_block.3.bias\", \"convolution_layers.18.convolution_block.4.weight\", \"convolution_layers.18.convolution_block.4.bias\", \"convolution_layers.18.convolution_block.4.running_mean\", \"convolution_layers.18.convolution_block.4.running_var\", \"convolution_layers.19.convolution_block.0.weight\", \"convolution_layers.19.convolution_block.0.bias\", \"convolution_layers.19.convolution_block.1.weight\", \"convolution_layers.19.convolution_block.1.bias\", \"convolution_layers.19.convolution_block.1.running_mean\", \"convolution_layers.19.convolution_block.1.running_var\", \"convolution_layers.19.convolution_block.3.weight\", \"convolution_layers.19.convolution_block.3.bias\", \"convolution_layers.19.convolution_block.4.weight\", \"convolution_layers.19.convolution_block.4.bias\", \"convolution_layers.19.convolution_block.4.running_mean\", \"convolution_layers.19.convolution_block.4.running_var\", \"dense_layers.3.weight\", \"dense_layers.3.bias\". \n\tUnexpected key(s) in state_dict: \"convolution_layers.3.convolution_block.0.weight\", \"convolution_layers.3.convolution_block.0.bias\", \"convolution_layers.3.convolution_block.2.weight\", \"convolution_layers.3.convolution_block.2.bias\", \"convolution_layers.4.convolution_block.2.weight\", \"convolution_layers.4.convolution_block.2.bias\", \"convolution_layers.5.convolution_block.2.weight\", \"convolution_layers.5.convolution_block.2.bias\", \"convolution_layers.6.convolution.weight\", \"convolution_layers.6.convolution.bias\", \"convolution_layers.6.convolution_block.2.weight\", \"convolution_layers.6.convolution_block.2.bias\", \"convolution_layers.7.convolution_block.0.weight\", \"convolution_layers.7.convolution_block.0.bias\", \"convolution_layers.7.convolution_block.2.weight\", \"convolution_layers.7.convolution_block.2.bias\", \"convolution_layers.8.convolution_block.2.weight\", \"convolution_layers.8.convolution_block.2.bias\", \"convolution_layers.9.convolution_block.2.weight\", \"convolution_layers.9.convolution_block.2.bias\", \"convolution_layers.10.convolution.weight\", \"convolution_layers.10.convolution.bias\", \"convolution_layers.10.convolution_block.2.weight\", \"convolution_layers.10.convolution_block.2.bias\", \"convolution_layers.11.convolution_block.0.weight\", \"convolution_layers.11.convolution_block.0.bias\", \"convolution_layers.11.convolution_block.2.weight\", \"convolution_layers.11.convolution_block.2.bias\", \"convolution_layers.12.convolution_block.2.weight\", \"convolution_layers.12.convolution_block.2.bias\", \"convolution_layers.13.convolution_block.2.weight\", \"convolution_layers.13.convolution_block.2.bias\", \"dense_layers.2.weight\", \"dense_layers.2.bias\". \n\tsize mismatch for convolution_layers.0.weight: copying a param with shape torch.Size([16, 1, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 1, 7, 7, 7]).\n\tsize mismatch for convolution_layers.4.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3, 3]).\n\tsize mismatch for convolution_layers.4.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for convolution_layers.5.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3, 3]).\n\tsize mismatch for convolution_layers.5.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for convolution_layers.6.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3, 3]).\n\tsize mismatch for convolution_layers.6.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for convolution_layers.8.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3, 3]).\n\tsize mismatch for convolution_layers.8.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for convolution_layers.9.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3, 3]).\n\tsize mismatch for convolution_layers.9.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for convolution_layers.10.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3, 3]).\n\tsize mismatch for convolution_layers.10.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for convolution_layers.12.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3, 3]).\n\tsize mismatch for convolution_layers.12.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for convolution_layers.13.convolution_block.0.weight: copying a param with shape torch.Size([16, 16, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3, 3]).\n\tsize mismatch for convolution_layers.13.convolution_block.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for dense_layers.0.weight: copying a param with shape torch.Size([32, 16]) from checkpoint, the shape in current model is torch.Size([1000, 512]).\n\tsize mismatch for dense_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1000])."
     ]
    }
   ],
   "source": [
    "cnn_group = CNN_Group(\n",
    "    num_sets_per_label={6_000 : 583, 24_000 : 145, 70_000 : 50},\n",
    "    num_sets_per_label_sensitivity=2_000,\n",
    "    num_bins_per_dimension=50, #nominal is 10, retrain det_bkg models with 50\n",
    "    q_squared_veto=Names_of_q_Squared_Vetos().resonances,\n",
    "    std_scale=True,\n",
    "    shuffle=True,\n",
    "    uniform_label_counts=True,\n",
    "    loss_fn=MSELoss(),\n",
    "    learning_rate=1e-3, # nominal 3e-4\n",
    "    learning_rate_scheduler_reduction_factor=0.97, # nominal 0.97\n",
    "    size_of_training_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    size_of_evaluation_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    number_of_epochs=50, # nominal 100\n",
    "    number_of_epochs_between_checkpoints=1,\n",
    "    results_table=results_table,\n",
    "    device=device,\n",
    "    bkg_fraction=0.44,\n",
    "    bkg_charge_fraction=0.57\n",
    ")\n",
    "\n",
    "# cnn_group.train_subset(levels=[Names_of_Levels().detector_and_background,], nums_events_per_set=(24_000,), remake_datasets=False)\n",
    "cnn_group.evaluate_all(remake_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\", Names_of_Levels().detector_and_background : \"Detector and Bkg.\"}\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(Names_of_Levels().tuple_, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    plot_linearity(\n",
    "        linearity_test_results=cnn_group.results[level][num_events_per_set].linearity_results, \n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {names_of_levels[level]}\"\n",
    "        f\"\\nEvents/set: {num_events_per_set}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{cnn_group.num_sets_per_label[num_events_per_set]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "# fig.suptitle(f\"CNN, bins/dim.: {cnn_group.num_bins_per_dimension}\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.suptitle(f\"CNN\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"cnn_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def plot_image_slices(\n",
    "    image,\n",
    "    norm, \n",
    "    cmap,\n",
    "    ax_3d,\n",
    "    num_slices=3, \n",
    "):  \n",
    "\n",
    "    def xy_plane_at(z_position):\n",
    "        x, y = numpy.indices(\n",
    "            (\n",
    "                axis_dimension_from_cartesian[\"x\"] + 1, \n",
    "                axis_dimension_from_cartesian[\"y\"] + 1\n",
    "            )\n",
    "        )\n",
    "        z = numpy.full(\n",
    "            (\n",
    "                axis_dimension_from_cartesian[\"x\"] + 1, \n",
    "                axis_dimension_from_cartesian[\"y\"] + 1\n",
    "            ), \n",
    "            z_position\n",
    "        )\n",
    "        return x, y, z\n",
    "    \n",
    "    def plot_slice(z_index):\n",
    "        x, y, z = xy_plane_at(z_index) \n",
    "        ax_3d.plot_surface(\n",
    "            x, y, z, \n",
    "            rstride=1, cstride=1, \n",
    "            facecolors=colors[:,:,z_index], \n",
    "            shade=False\n",
    "        )\n",
    "\n",
    "    def plot_outline(z_index, offset=0.3):\n",
    "        x, y, z = xy_plane_at(z_index - offset)\n",
    "        ax_3d.plot_surface(\n",
    "            x, y, z, \n",
    "            rstride=1, \n",
    "            cstride=1, \n",
    "            shade=False,\n",
    "            color=\"#f2f2f2\",\n",
    "            edgecolor=\"#f2f2f2\"\n",
    "        )\n",
    "\n",
    "    image = image.squeeze().cpu()\n",
    "    colors = cmap(norm(image))\n",
    "    \n",
    "    axis_index_from_cartesian = {\n",
    "        \"x\": 0,\n",
    "        \"y\": 1,\n",
    "        \"z\": 2\n",
    "    }\n",
    "    axis_dimension_from_cartesian = {\n",
    "        \"x\": image.shape[axis_index_from_cartesian[\"x\"]],\n",
    "        \"y\": image.shape[axis_index_from_cartesian[\"y\"]],\n",
    "        \"z\": image.shape[axis_index_from_cartesian[\"z\"]]\n",
    "    }\n",
    "    z_indices = numpy.linspace( \n",
    "        start=0, \n",
    "        stop=axis_dimension_from_cartesian[\"z\"]-1, \n",
    "        num=num_slices, \n",
    "        dtype=int  # forces integer indices\n",
    "    ) \n",
    "    for i in z_indices:\n",
    "        plot_outline(i)\n",
    "        plot_slice(i)\n",
    "\n",
    "\n",
    "    ax_labels = {\n",
    "        \"x\": r\"$\\cos\\theta_\\mu$\",\n",
    "        \"y\": r\"$\\cos\\theta_K$\",\n",
    "        \"z\": r\"$\\chi$\"\n",
    "    }\n",
    "    # ax_3d.set_axis_off()\n",
    "    ax_3d.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        bottom=False,\n",
    "        top=True,\n",
    "        labelbottom=False,\n",
    "        labeltop=False,\n",
    "        labelleft=False,\n",
    "        labelright=False\n",
    "    )\n",
    "    ax_3d.set_xlabel(ax_labels[\"x\"], labelpad=-16)\n",
    "    ax_3d.set_ylabel(ax_labels[\"y\"], labelpad=-16)\n",
    "    ax_3d.set_zlabel(ax_labels[\"z\"], labelpad=-16)\n",
    "    # ax_3d.set_box_aspect(None, zoom=0.85)\n",
    "    \n",
    "\n",
    "for delta_c9 in (delta_C9_value_standard_model, delta_C9_value_new_physics):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, subplot_kw={\"projection\":\"3d\"}, layout=\"compressed\")\n",
    "    norm = mpl.colors.Normalize(vmin=-1, vmax=1)\n",
    "    cmap = plt.cm.magma\n",
    "    cbar = fig.colorbar(\n",
    "        mpl.cm.ScalarMappable(norm=norm, cmap=cmap), \n",
    "        ax=axs, \n",
    "        location=\"right\", \n",
    "        shrink=0.6,     \n",
    "    )\n",
    "    cbar.set_label(r\"Normalized ${q^2}$ (Avg.)\", size=11)\n",
    "    cbar.set_ticks([])\n",
    "        \n",
    "    levels = (Names_of_Levels().generator, Names_of_Levels().detector)\n",
    "    names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\"}\n",
    "\n",
    "    for (level, num_events_per_set), ax in zip(product(levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "\n",
    "        dataset = Images_Dataset(settings=cnn_group.get_individual(level=level, num_events_per_set=num_events_per_set).evaluation_dataset_settings)\n",
    "        dataset.load()\n",
    "        plot_image_slices(\n",
    "            image=dataset.features[dataset.labels==delta_c9][0],\n",
    "            norm=norm,\n",
    "            cmap=cmap,\n",
    "            ax_3d=ax\n",
    "        )\n",
    "        ax.set_title(\n",
    "            (\n",
    "                f\"Level: {names_of_levels[level]}\"\n",
    "                f\"\\nEvents: {num_events_per_set}\"\n",
    "            ),\n",
    "            loc=\"left\",\n",
    "            y=0.97\n",
    "        )\n",
    "\n",
    "    delta_c9_description = (\n",
    "        r\"SM ($\\delta C_9 = \" + f\"{delta_C9_value_standard_model}\" + r\"$)\" if delta_c9 == delta_C9_value_standard_model\n",
    "        else r\"NP ($\\delta C_9 = \" + f\"{delta_C9_value_new_physics}\" + r\"$)\" if delta_c9 == delta_C9_value_new_physics\n",
    "        else None\n",
    "    )\n",
    "    if delta_c9_description is None: raise ValueError\n",
    "\n",
    "    fig.suptitle(\n",
    "        (\n",
    "            f\"Images, \"\n",
    "            + f\"bins/dim.: {cnn_group.num_bins_per_dimension}, \"\n",
    "            + delta_c9_description\n",
    "            + \"\\n\"\n",
    "        ), \n",
    "        x=0.02, \n",
    "        horizontalalignment=\"left\"\n",
    "    )\n",
    "\n",
    "    save_name = (\n",
    "        \"image_grid_SM.png\" if delta_c9 == delta_C9_value_standard_model\n",
    "        else \"image_grid_NP.png\" if delta_c9 == delta_C9_value_new_physics\n",
    "        else None\n",
    "    )\n",
    "    if save_name is None: raise ValueError\n",
    "\n",
    "    plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(save_name), bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event-by-event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_by_event_group = Event_by_Event_Group(\n",
    "    num_evaluation_sets_per_label={6_000 : 583, 24_000 : 145, 70_000 : 50},\n",
    "    num_evaluation_sets_per_label_sensitivity=2_000,\n",
    "    q_squared_veto=Names_of_q_Squared_Vetos().resonances,\n",
    "    std_scale=True,\n",
    "    shuffle=True,\n",
    "    uniform_label_counts=True,\n",
    "    loss_fn=CrossEntropyLoss(),\n",
    "    learning_rate=3e-3,\n",
    "    learning_rate_scheduler_reduction_factor=0.95,\n",
    "    size_of_training_batch=10_000,\n",
    "    size_of_evaluation_batch=10_000,\n",
    "    number_of_epochs=300,\n",
    "    number_of_epochs_between_checkpoints=2,\n",
    "    results_table=results_table,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# event_by_event_group.train_subset(levels=[Names_of_Levels().detector], remake_datasets=True)\n",
    "event_by_event_group.evaluate_all(remake_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\"}\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(event_by_event_group.possible_levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    plot_linearity(\n",
    "        linearity_test_results=event_by_event_group.results[level][num_events_per_set].linearity_results, \n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {names_of_levels[level]}\"\n",
    "        f\"\\nEvents/set: {num_events_per_set}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{event_by_event_group.num_evaluation_sets_per_label[num_events_per_set]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "fig.suptitle(\"Event-by-event\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"ebe_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(event_by_event_group.possible_levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    dataset = Binned_Sets_Dataset(settings=event_by_event_group.get_individual(level)._get_evaluation_set_dataset_settings(num_events_per_set))\n",
    "    dataset.load()\n",
    "\n",
    "    plot_log_probability_distribution_examples(\n",
    "        log_probabilities=event_by_event_group.results[level][num_events_per_set].log_probabilities, \n",
    "        binned_labels=dataset.labels,\n",
    "        bin_map=dataset.bin_map,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Level: {names_of_levels[level]}\\nEvents: {num_events_per_set}\", loc=\"left\")\n",
    "\n",
    "axs.flat[0].legend(loc=\"lower right\", markerscale=2)\n",
    "fig.suptitle(\"Event-by-event\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"$\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"$\\log\\;p(\\delta C_9 | x_1, ..., x_N)$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"ebe_grid_proba.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_train = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_train.pkl\")\n",
    "mix_train = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_train.pkl\")\n",
    "all_train = pandas.concat([charge_train, mix_train])\n",
    "\n",
    "charge_eval = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_eval.pkl\")\n",
    "mix_eval = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_eval.pkl\")\n",
    "all_eval = pandas.concat([charge_eval, mix_eval])\n",
    "\n",
    "charge_eval = apply_q_squared_veto(charge_eval, Names_of_q_Squared_Vetos().resonances)\n",
    "charge_train = apply_q_squared_veto(charge_train, Names_of_q_Squared_Vetos().resonances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
