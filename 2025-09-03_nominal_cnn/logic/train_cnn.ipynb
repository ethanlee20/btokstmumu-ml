{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from btokstmumu_ml_helpers.datasets.constants import Names_of_Levels, Names_of_q_Squared_Vetos, Numbers_of_Events_per_Set\n",
    "from btokstmumu_ml_helpers.experiment.experiment import CNN_Group\n",
    "from btokstmumu_ml_helpers.experiment.results_table import Results_Table\n",
    "from btokstmumu_ml_helpers.experiment.constants import Paths_to_Directories\n",
    "from btokstmumu_ml_helpers.models.hardware_util import select_device\n",
    "from btokstmumu_ml_helpers.plot.linearity import plot_linearity\n",
    "\n",
    "results_table = Results_Table()\n",
    "device = select_device()\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "mpl.rcParams[\"figure.dpi\"] = 400\n",
    "mpl.rcParams[\"axes.titlesize\"] = 8\n",
    "mpl.rcParams[\"figure.titlesize\"] = 8\n",
    "mpl.rcParams[\"figure.labelsize\"] = 30\n",
    "mpl.rcParams[\"text.usetex\"] = True\n",
    "mpl.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{bm}\"\n",
    "mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "mpl.rcParams[\"font.serif\"] = [\"Computer Modern\"]\n",
    "mpl.rcParams[\"font.size\"] = 8\n",
    "mpl.rcParams[\"axes.titley\"] = None\n",
    "mpl.rcParams[\"axes.titlepad\"] = 2\n",
    "mpl.rcParams[\"legend.fancybox\"] = False\n",
    "mpl.rcParams[\"legend.framealpha\"] = 0\n",
    "mpl.rcParams[\"legend.markerscale\"] = 1\n",
    "mpl.rcParams[\"legend.fontsize\"] = 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_group = CNN_Group(\n",
    "    model_variant=\"nominal\",\n",
    "    num_sets_per_label={6_000 : 583, 24_000 : 145, 70_000 : 50},\n",
    "    num_sets_per_label_sensitivity=2_000,\n",
    "    num_bins_per_dimension=10, #nominal is 10, retrain det_bkg models with 50\n",
    "    q_squared_veto=Names_of_q_Squared_Vetos().resonances,\n",
    "    std_scale=True,\n",
    "    shuffle=True,\n",
    "    uniform_label_counts=True,\n",
    "    loss_fn=MSELoss(),\n",
    "    learning_rate=3e-4, # nominal 3e-4\n",
    "    learning_rate_scheduler_reduction_factor=0.9, # nominal 0.97\n",
    "    learning_rate_scheduler_patience=3,\n",
    "    size_of_training_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    size_of_evaluation_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    number_of_epochs=50, # nominal 100\n",
    "    number_of_epochs_between_checkpoints=1,\n",
    "    results_table=results_table,\n",
    "    device=device,\n",
    "    bkg_fraction=0.44,\n",
    "    bkg_charge_fraction=0.57,\n",
    "    path_to_common_processed_datasets_dir=\"../../common/state/data/processed\",\n",
    "    path_to_local_processed_datasets_dir=\"../state/data\",\n",
    "    path_to_local_models_dir=\"../state/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making images dataset.\n",
      "Applying signal preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared          0\n",
      "costheta_mu      170\n",
      "costheta_K       760\n",
      "chi              760\n",
      "dc9                0\n",
      "dc9_bin_index      0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Reducing events per label to lowest per label.\n",
      "Shuffled dataframe.\n",
      "Reduced events per label to lowest per label.\n",
      "Applied signal preprocessing.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying background preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applied background preprocessing.\n",
      "Applying background preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applied background preprocessing.\n",
      "Saved tensor of shape: torch.Size([6380, 1, 10, 10, 10]) to ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_train_features.pt\n",
      "Saved tensor of shape: torch.Size([6380]) to ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_train_labels.pt\n",
      "Made images dataset.\n",
      "Making images dataset.\n",
      "Applying signal preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared          0\n",
      "costheta_mu      168\n",
      "costheta_K       706\n",
      "chi              706\n",
      "dc9                0\n",
      "dc9_bin_index      0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Reducing events per label to lowest per label.\n",
      "Shuffled dataframe.\n",
      "Reduced events per label to lowest per label.\n",
      "Applied signal preprocessing.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_val.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_val.parquet\n",
      "Applying background preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applied background preprocessing.\n",
      "Applying background preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applied background preprocessing.\n",
      "Saved tensor of shape: torch.Size([6380, 1, 10, 10, 10]) to ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_features.pt\n",
      "Saved tensor of shape: torch.Size([6380]) to ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_labels.pt\n",
      "Made images dataset.\n",
      "Loaded tensor of shape: torch.Size([6380, 1, 10, 10, 10]) from ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_train_features.pt\n",
      "Loaded tensor of shape: torch.Size([6380]) from ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_train_labels.pt\n",
      "Loaded tensor of shape: torch.Size([6380, 1, 10, 10, 10]) from ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_features.pt\n",
      "Loaded tensor of shape: torch.Size([6380]) from ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_labels.pt\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 0.9362398470593368\n",
      "    Eval loss: 0.7189158461669537\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 0.3626122920593563\n",
      "    Eval loss: 0.16750196130011663\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 0.16596602940517446\n",
      "    Eval loss: 0.28848343293537265\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 0.15568707135263013\n",
      "    Eval loss: 0.13426764276843742\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 0.13176631508624\n",
      "    Eval loss: 0.13211694405834845\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 0.12153456228031884\n",
      "    Eval loss: 0.11869859049653592\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 0.11188851257480208\n",
      "    Eval loss: 0.10670001513856461\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 0.10412679689631604\n",
      "    Eval loss: 0.15572089747700954\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 0.10643872461808003\n",
      "    Eval loss: 0.10488118565458372\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 0.10411107935548518\n",
      "    Eval loss: 0.10575824387810431\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 0.11708287876286319\n",
      "    Eval loss: 0.11252306446011058\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 0.09990123518726289\n",
      "    Eval loss: 0.0997953872844714\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 0.09081550255232113\n",
      "    Eval loss: 0.1252787602735466\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 0.09217129689809607\n",
      "    Eval loss: 0.10365447683616075\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 0.09343349321480651\n",
      "    Eval loss: 0.09740830095223449\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 0.08191574229711554\n",
      "    Eval loss: 0.10690253122709048\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 0.08762985634455395\n",
      "    Eval loss: 0.1252460731024455\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 0.08334443045636798\n",
      "    Eval loss: 0.08234349741267688\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 0.09079363701490299\n",
      "    Eval loss: 0.08720272845591896\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 0.07970826687448185\n",
      "    Eval loss: 0.08728258582945499\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 0.09029413874565634\n",
      "    Eval loss: 0.09853221480325217\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 0.07253777910026135\n",
      "    Eval loss: 0.0808997912527203\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 0.07081579418814313\n",
      "    Eval loss: 0.07577260368693409\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 0.07089574426973963\n",
      "    Eval loss: 0.07373564920710127\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 0.06556005440449557\n",
      "    Eval loss: 0.08457867570975657\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 0.06299320191170237\n",
      "    Eval loss: 0.07709835901511178\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 0.0655121831076217\n",
      "    Eval loss: 0.08309517341442439\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 0.0663121921087879\n",
      "    Eval loss: 0.07189611844871911\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 0.061422780227203884\n",
      "    Eval loss: 0.0732285250627702\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 0.06325753728752473\n",
      "    Eval loss: 0.07241024575654019\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 0.060090565843830955\n",
      "    Eval loss: 0.07497579276848763\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 0.062183824721881484\n",
      "    Eval loss: 0.06835389834796293\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 0.05962801654754957\n",
      "    Eval loss: 0.0667618094904777\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 0.05765632932050235\n",
      "    Eval loss: 0.07220221978956716\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 0.06133818973529466\n",
      "    Eval loss: 0.08127200474299302\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 0.06084539529010676\n",
      "    Eval loss: 0.07343064901845996\n",
      "\n",
      "Learning rate: [0.0003]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 0.058250132351890874\n",
      "    Eval loss: 0.0842832499790295\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 0.05919976802392941\n",
      "    Eval loss: 0.07127780275367261\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 0.0545654588020289\n",
      "    Eval loss: 0.0712015885009487\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 0.06014072254464648\n",
      "    Eval loss: 0.06550170310207941\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 0.056009156279075004\n",
      "    Eval loss: 0.06687000277299371\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 0.05417415658995106\n",
      "    Eval loss: 0.06741434209592667\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 0.055023900919814656\n",
      "    Eval loss: 0.06522124410130924\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 0.05584527938606277\n",
      "    Eval loss: 0.0697513249682616\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 0.057185885152484836\n",
      "    Eval loss: 0.0794461340930523\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 0.056980672821335045\n",
      "    Eval loss: 0.0642991782911246\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 0.05065200195063052\n",
      "    Eval loss: 0.06475692214899255\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 0.051783428759234015\n",
      "    Eval loss: 0.06915690727427262\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 0.053337716588098334\n",
      "    Eval loss: 0.07997831700320607\n",
      "\n",
      "Learning rate: [0.00027]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 0.05588566325830854\n",
      "    Eval loss: 0.0645000216465415\n",
      "\n",
      "Learning rate: [0.000243]\n",
      "Peak GPU memory usage:\n",
      "0.43773 GB\n",
      "Completed checkpoint at epoch: {ep}\n",
      "Completed training.\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n"
     ]
    }
   ],
   "source": [
    "cnn_group.train_subset(levels=[Names_of_Levels().detector_and_background,], nums_events_per_set=(24_000,), remake_datasets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making images dataset.\n",
      "Applying signal preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared          0\n",
      "costheta_mu      168\n",
      "costheta_K       706\n",
      "chi              706\n",
      "dc9                0\n",
      "dc9_bin_index      0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Reducing events per label to lowest per label.\n",
      "Shuffled dataframe.\n",
      "Reduced events per label to lowest per label.\n",
      "Applied signal preprocessing.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_val.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_val.parquet\n",
      "Applying background preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applied background preprocessing.\n",
      "Applying background preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applied background preprocessing.\n",
      "Saved tensor of shape: torch.Size([6380, 1, 10, 10, 10]) to ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_features.pt\n",
      "Saved tensor of shape: torch.Size([6380]) to ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_labels.pt\n",
      "Made images dataset.\n",
      "Making images dataset.\n",
      "Applying signal preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared          0\n",
      "costheta_mu      168\n",
      "costheta_K       706\n",
      "chi              706\n",
      "dc9                0\n",
      "dc9_bin_index      0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applying label subset.\n",
      "Applied label subset.\n",
      "Reducing events per label to lowest per label.\n",
      "Shuffled dataframe.\n",
      "Reduced events per label to lowest per label.\n",
      "Applied signal preprocessing.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_val.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_val.parquet\n",
      "Applying background preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applied background preprocessing.\n",
      "Applying background preprocessing.\n",
      "Removing rows that have a NaN.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed rows that have a NaN.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying standand scale.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\charge_sb_bkg_train.parquet\n",
      "Loaded background file: ..\\..\\common\\state\\data\\processed\\aggregated_generic\\mix_sb_bkg_train.parquet\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applying q^2 veto.\n",
      "Applied q^2 veto.\n",
      "Applied standard scale.\n",
      "Shuffled dataframe.\n",
      "Applied background preprocessing.\n",
      "Saved tensor of shape: torch.Size([2000, 1, 10, 10, 10]) to ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_sens_features.pt\n",
      "Saved tensor of shape: torch.Size([2000]) to ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_sens_labels.pt\n",
      "Made images dataset.\n",
      "Loaded tensor of shape: torch.Size([6380, 1, 10, 10, 10]) from ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_features.pt\n",
      "Loaded tensor of shape: torch.Size([6380]) from ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\state\\data\\images_det_bkg_q2v_resonances\\24000_val_sens_labels.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tetha\\Desktop\\btokstmumu-ml\\common\\logic\\btokstmumu_ml_helpers\\experiment\\results_table.py:49: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unloaded datasets.\n",
      "Unloaded datasets.\n"
     ]
    }
   ],
   "source": [
    "cnn_group.evaluate_subset(levels=[Names_of_Levels().detector_and_background], nums_events_per_set=[24_000,], remake_datasets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\", Names_of_Levels().detector_and_background : \"Detector and Bkg.\"}\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(Names_of_Levels().tuple_, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    plot_linearity(\n",
    "        linearity_test_results=cnn_group.results[level][num_events_per_set].linearity_results, \n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {names_of_levels[level]}\"\n",
    "        f\"\\nEvents/set: {num_events_per_set}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{cnn_group.num_sets_per_label[num_events_per_set]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "# fig.suptitle(f\"CNN, bins/dim.: {cnn_group.num_bins_per_dimension}\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.suptitle(f\"CNN\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"cnn_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_dir = Path(\"../state/plots\")\n",
    "\n",
    "names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\", Names_of_Levels().detector_and_background : \"Detector and Bkg.\"}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "level = Names_of_Levels().detector_and_background\n",
    "num_events_per_set = 24_000\n",
    "\n",
    "plot_linearity(\n",
    "    linearity_test_results=cnn_group.results[level][num_events_per_set].linearity_results,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "    f\"Level: {names_of_levels[level]}\"\n",
    "    f\"\\nEvents/set: {num_events_per_set}\"\n",
    "    \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{cnn_group.num_sets_per_label[num_events_per_set]}\", \n",
    "    loc=\"left\"\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "fig.suptitle(f\"CNN\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "ax.set_xlabel(r\"Actual $\\delta C_9$\", fontsize=11)\n",
    "ax.set_ylabel(r\"Predicted $\\delta C_9$\", fontsize=11)\n",
    "\n",
    "plt.savefig(plots_dir.joinpath(f\"cnn_lin_{level}_{num_events_per_set}.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
