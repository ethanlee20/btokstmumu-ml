{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d8e24e",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157470bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product \n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"train\", \"val\"]\n",
    "levels = [\"gen\", \"det\", \"det_bkg\"]\n",
    "\n",
    "dset_name = \"images\"\n",
    "\n",
    "def make_model_name(level, num_signal): return f\"cnn_{level}_{num_signal}\"\n",
    "\n",
    "dc9_new_phys = -0.82\n",
    "\n",
    "bins_per_dim = 50\n",
    "num_signal_per_set = [8_000, 16_000, 32_000]\n",
    "num_sets_per_label = {8_000 : 400, 16_000: 200, 32_000 : 100} \n",
    "num_sets_sensitivity = 2_000\n",
    "bkg_signal_ratio = 0.79\n",
    "charge_bkg_fraction = 0.57\n",
    "\n",
    "device = helpers.models.select_device()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "lr = 1e-3\n",
    "lr_reduce_factor = 0.2\n",
    "lr_reduce_patience = 5\n",
    "batch_sizes = {8_000 : 128, 16_000 : 64, 32_000 : 32}\n",
    "epochs = 50\n",
    "epochs_checkpoint = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f762b51",
   "metadata": {},
   "source": [
    "Save standard scaling constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"train\"\n",
    "\n",
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "        images_features, images_labels = helpers.data.make_images(\n",
    "            level,\n",
    "            split,\n",
    "            num_signal,\n",
    "            num_sets_per_label[num_signal],\n",
    "            bins_per_dim,\n",
    "            bkg_signal_ratio=bkg_signal_ratio,\n",
    "            charge_bkg_fraction=charge_bkg_fraction\n",
    "        )\n",
    "\n",
    "        std_scale_mean = torch.mean(images_features)\n",
    "        std_scale_std = torch.std(images_features)\n",
    "\n",
    "        helpers.data.save_dset_file(std_scale_mean, dset_name, level, split, \"mean\", num_signal_per_set=num_signal)\n",
    "        helpers.data.save_dset_file(std_scale_std, dset_name, level, split, \"std\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c0fe9",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a613e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal, split in product(levels, num_signal_per_set, splits): \n",
    "\n",
    "    images_features, images_labels = helpers.data.make_images(\n",
    "        level,\n",
    "        split,\n",
    "        num_signal,\n",
    "        num_sets_per_label[num_signal],\n",
    "        bins_per_dim,\n",
    "        bkg_signal_ratio=bkg_signal_ratio,\n",
    "        charge_bkg_fraction=charge_bkg_fraction\n",
    "    )\n",
    "\n",
    "    images_features = helpers.data.apply_std_scale(images_features, dset_name, level, num_signal_per_set=num_signal)\n",
    "\n",
    "    helpers.data.save_dset_file(images_features, dset_name, level, split, \"features\", num_signal_per_set=num_signal)\n",
    "    helpers.data.save_dset_file(images_labels, dset_name, level, split, \"labels\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9934507c",
   "metadata": {},
   "source": [
    "Sensitivity datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "\n",
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    images_features, images_labels = helpers.data.make_images(\n",
    "        level,\n",
    "        split,\n",
    "        num_signal,\n",
    "        num_sets_sensitivity,\n",
    "        bins_per_dim,\n",
    "        label_subset=[dc9_new_phys],\n",
    "        bkg_signal_ratio=bkg_signal_ratio,\n",
    "        charge_bkg_fraction=charge_bkg_fraction\n",
    "    )\n",
    "\n",
    "    images_features = helpers.data.apply_std_scale(images_features, dset_name, level, num_signal_per_set=num_signal)\n",
    "\n",
    "    helpers.data.save_dset_file(images_features, dset_name, level, split, \"sens_features\", num_signal_per_set=num_signal)\n",
    "    helpers.data.save_dset_file(images_labels, dset_name, level, split, \"sens_labels\", num_signal_per_set=num_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e4940",
   "metadata": {},
   "source": [
    "Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36149219",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model = helpers.models.CNN_Model()\n",
    "\n",
    "    model_name = f\"cnn_{level}_{num_signal}\"\n",
    "\n",
    "    dataset_train = helpers.data.Dataset(dset_name, level, \"train\", num_signal_per_set=num_signal)\n",
    "    dataset_val = helpers.data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal)\n",
    "    \n",
    "    helpers.models.train(\n",
    "        model,\n",
    "        model_name,\n",
    "        loss_fn,\n",
    "        dataset_train,\n",
    "        dataset_val,\n",
    "        device,\n",
    "        lr,\n",
    "        lr_reduce_factor,\n",
    "        lr_reduce_patience,\n",
    "        batch_sizes[num_signal],\n",
    "        batch_sizes[num_signal],\n",
    "        epochs,\n",
    "        epochs_checkpoint\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c41044",
   "metadata": {},
   "source": [
    "Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512d5f7",
   "metadata": {},
   "source": [
    "Linearity and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2404cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "    model = helpers.models.CNN_Model()\n",
    "    model.load_state_dict(helpers.models.open_model_state_dict(model_name))\n",
    "    \n",
    "    dataset_val = helpers.data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal)\n",
    "    \n",
    "    preds = helpers.models.predict_values_set_model(model, dataset_val.features, device)\n",
    "\n",
    "    results_lin = helpers.models.run_linearity_test(preds, dataset_val.labels)\n",
    "    results_err = helpers.models.run_error_test(preds, dataset_val.labels)\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "    helpers.models.save_test_result(results_lin, \"lin\", num_signal, model_name)\n",
    "    helpers.models.save_test_result(results_err, \"err\", num_signal, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908d9e8",
   "metadata": {},
   "source": [
    "Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level, num_signal in product(levels, num_signal_per_set):\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "    model = helpers.models.CNN_Model()\n",
    "    model.load_state_dict(helpers.models.open_model_state_dict(model_name))\n",
    "\n",
    "    dataset_val_sens = helpers.data.Dataset(dset_name, level, \"val\", num_signal_per_set=num_signal, sensitivity=True)\n",
    "\n",
    "    preds = helpers.models.predict_values_set_model(model, dataset_val_sens.features, device)\n",
    "\n",
    "    results_sens = helpers.models.run_sensitivity_test(preds, dataset_val_sens.labels)\n",
    "\n",
    "    model_name = make_model_name(level, num_signal)\n",
    "    helpers.models.save_test_result(results_sens, \"sens\", num_signal, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cea4f",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd675576",
   "metadata": {},
   "source": [
    "Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "fancy_level_names = {\n",
    "    \"gen\": \"Generator\", \n",
    "    \"det\" : \"Detector\", \n",
    "    \"det_bkg\" : \"Detector and Bkg.\"\n",
    "}\n",
    "\n",
    "for (level, num_signal), ax in zip(product(levels, num_signal_per_set), axs.flat):\n",
    "    \n",
    "    model_name = make_model_name(level, num_signal)\n",
    "\n",
    "    result = helpers.models.open_test_result(\"lin\", num_signal, model_name)\n",
    "\n",
    "    helpers.plot.plot_linearity(result, ax=ax)\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {fancy_level_names[level]}\"\n",
    "        f\"\\nEvents/set: {num_signal}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{num_sets_per_label[num_signal]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "fig.suptitle(f\"CNN\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Path(\"plots\").joinpath(\"cnn_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
